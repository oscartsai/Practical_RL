{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8: sequence learning\n",
    "\n",
    "\n",
    "This time we'll solve a problem of transribing english words, also known as g2p (grapheme2phoneme)\n",
    "\n",
    " * word (sequence of letters in source language) -> translation (sequence of letters in target language)\n",
    "\n",
    "\n",
    " \n",
    "Some letters correspond to several phonemes and others - to none, so we use encoder-decoder architecture to figure that out.\n",
    "\n",
    "This kind of architectures is about converting anything to anything, including\n",
    " * Machine translation and spoken dialogue systems\n",
    " * [Image captioning](http://mscoco.org/dataset/#captions-challenge2015) and [image2latex](https://openai.com/requests-for-research/#im2latex) (convolutional encoder, recurrent decoder)\n",
    " * Generating [images by captions](https://arxiv.org/abs/1511.02793) (recurrent encoder, convolutional decoder)\n",
    " * Grapheme2phoneme - convert words to transcripts\n",
    " \n",
    " \n",
    "We chose simplified __Hebrew->English__ machine translation for words and short phrases (character-level), as it is relatively quick to train even without gpu cluster.\n",
    "\n",
    "Since you have already done step1-2 in RNN assignment, we trust you to __read carefully__ through already implemented functions instead of reimplementing them for the third time.\n",
    "\n",
    "__Contributions:__ This notebook is brought to you by\n",
    "* Yandex [MT team](https://tech.yandex.com/translate/)\n",
    "* Oleg Vasilev ([Omrigan](https://github.com/Omrigan/)), Dmitry Emelyanenko ([TixFeniks](https://github.com/tixfeniks)) and Fedor Ratnikov ([justheuristic](https://github.com/justheuristic/))\n",
    "* Dataset is parsed from [Wiktionary](https://en.wiktionary.org), which is under CC-BY-SA and GFDL licenses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EASY_MODE = True        #If True, only translates phrases shorter than 20 characters (way easier).\n",
    "                        #Useful for initial coding.\n",
    "                        #If false, works with all phrases (please switch to this mode for homework assignment)\n",
    "\n",
    "MODE = \"he-to-en\"                                #way we translate. Either \"he-to-en\" or \"en-to-he\"\n",
    "END = ';'                                        #end of phrase for both source and target\n",
    "MAX_OUTPUT_LENGTH = 50 if not EASY_MODE else 20  #maximal length of _generated_ output, does not affect training\n",
    "REPORT_FREQ       = 100                          #how often to evaluate validation score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: preprocessing\n",
    "\n",
    "We shall store dataset as a dictionary\n",
    "`{ word1:[translation1,translation2,...], word2:[...],...}`.\n",
    "\n",
    "This is mostly due to the fact that many words have several correct translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size =  130699\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "word_to_translation = defaultdict(list) #our dictionary\n",
    "\n",
    "with open(\"main_dataset.txt\", encoding='UTF-8') as fin:\n",
    "    for line in fin:\n",
    "        \n",
    "        ###\n",
    "        #you may want to cast everything to unicode later during homework phase, just make sure you do it _everywhere_\n",
    "        ###\n",
    "\n",
    "        en, he = line[:-1].lower().replace(END, ' ').split('\\t')\n",
    "        word, trans = (he, en) if MODE == 'he-to-en' else (en, he)\n",
    "                \n",
    "        if EASY_MODE:\n",
    "            if max(len(word), len(trans)) > 20:\n",
    "                continue\n",
    "        \n",
    "        word_to_translation[word+END].append(trans+END)\n",
    "\n",
    "print (\"size = \", len(word_to_translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all unique letters in source language (a.k.a. source dictionary)\n",
    "all_words = list(word_to_translation.keys())\n",
    "\n",
    "source_letters = list(set(''.join(all_words)))\n",
    "source_to_ix = {l: i for i, l in enumerate(source_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all unique translation letters (a.k.a. target dictionary)\n",
    "\n",
    "all_translations = [ts for all_ts in word_to_translation.values() for ts in all_ts]\n",
    "\n",
    "target_letters = list(set([l for ts in all_translations for l in ts]+[\" \"]))\n",
    "target_to_ix = {l:i for i, l in enumerate(target_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special tokens\n",
    "PAD_ix = -1\n",
    "EOS_ix_source = source_letters.index(END)\n",
    "EOS_ix_target = target_letters.index(END)\n",
    "BOS_ix_target = target_letters.index(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw word/translation length distributions to estimate the scope of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAEICAYAAACtc9bVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGrBJREFUeJzt3XuwZWV55/HvT5DECwpID6Nc0hg7OuhMjOkAuUpEuahJ\nM1XGoKnYOsz0zAQzyWiNQpIpTAwZzEUSRuMMBgIYlRCSDB0hki4UL6mANEqpgIQOgnTbQEtzMWJI\nWp/5Y71HN8fT9Omzz22/5/upOrXXete71npX7373817WXjtVhSRJ6sMTlroAkiRp/hjYJUnqiIFd\nkqSOGNglSeqIgV2SpI4Y2CVJ6oiBXYsqyduS/MlSl0PStyW5KMlvjrH/PyZ59nyWSXNnYJekZSLJ\nnUleutTleDxJrk3yH0fTquqpVXXHUpVJj2Vg14LIwP9f0jxJsu9Sl0GTwQ9eAZDkDUn+amT99iR/\nNrJ+d5IXJvmRJDckeai9/shInmuTnJ3kb4FHgGcnOTLJx5J8Nckm4OCR/N+d5E+S3J/kwXa8Qxbp\nkqVlJcn7gCOAv2pD229JUklOS/Il4CMt358luafVwY8nef7IMS5K8u4kV7Y6d32S723bkuTcJPcl\neTjJ55K8YIZyHJjkQ0l2JHmgLR/Wtp0N/DjwrlbGd7X0SvKctvz0JJe0/e9K8mtTjfwkr0/yySS/\n2479xSQnj5z79UnuaGX/YpKfW6B/7q4Z2DXlY8CPJ3lCkmcB+wE/DNDmzp4KfAm4EjgPeAbwTuDK\nJM8YOc7PAxuA/YG7gA8ANzIE9LcD60fyrgeeDhzejvdfgK8v0PVJy1pV/TxDHfupqnoqcFnb9GLg\n3wAntvW/BtYA/wr4NPD+aYc6Ffh14EBgC3B2Sz8B+Ang+xjq3auB+2coyhOAPwa+h6Gh8XXgXa2M\nvwp8AnhjG35/4wz7/+92/Ge3sr8OeMPI9mOA2xg+E34buKA1Op7C8NlyclXtD/wIcNMMx9ceGNgF\nQJsf+yrwQobKfzXw5STPY6icnwBeAdxeVe+rql1V9UHgC8BPjRzqoqq6uap2Ac8Efgj4n1X1aFV9\nHPirkbz/whDQn1NV36iqG6vq4QW+VGnSvK2qvlZVXweoqgur6qtV9SjwNuD7kzx9JP9fVtWnWh18\nP0OdhqG+7Q88D0hV3VpV26efrKrur6o/r6pHquqrDA2DF8+moEn2YWhYnNnKeCfwewwN/il3VdV7\nq+obwMUMnxNTI3XfBF6Q5ElVtb2qbp7NefVYBnaN+hhwHENg/xhwLUOFfnFbfxZDL3zUXcChI+t3\njyw/C3igqr42Lf+U9zE0IC5N8uUkv53kieNfhtSVb9WpJPskOSfJPyR5GLizbTp4JP89I8uPMIy2\nUVUfYeh5vxu4L8n5SZ42/WRJnpzk/7Zh9IeBjwMHtKC9JwcDT+Sx9Xz6Z8S3yldVj7TFp7bPiZ9l\nGLnb3qYTnjeLc2oaA7tGTQX2H2/LH+Oxgf3LDMNzo44Ato2sj/5c4HbgwDbENpp/yFj1L1X161V1\nFMOw2ysZhu2klWqmn9scTXstsA54KcNw9+qWnlkdvOq8qvpB4CiGIfn/MUO2NwPPBY6pqqcxNPRH\nz/F4Pwn6FYaRgdHPiemfEY9Xvqur6mUMvfgvAO+dzX56LAO7Rn0M+EngSVW1lWH4/SSG4fLPAFcB\n35fktUn2TfKzDB8QH5rpYFV1F7AZ+PUk+yX5MUaG7ZP8ZJJ/23oCDzN8IHxz4S5PWvbuZZib3p39\ngUcZ5safDPzWbA+c5IeSHNNGxb4G/BMz17f9GebVH0xyEHDWbMvYhtcvA85Osn+S7wHeBOzx2RVJ\nDkmyrnUEHgX+cTfl0x4Y2PUtVfX3DJXpE239YeAO4G/bHPj9DL3qNzN8sLwFeGVVfeVxDvtahptl\ndjJ8QFwysu1fA5czBPVbGRoW75vPa5ImzP8Cfi3Jg8CrZth+CcPQ9jbgFuC6vTj20xh6wA+0Y9wP\n/M4M+X4feBJD7/s64MPTtv8B8Kp2V/t5M+z/iwwNhzuATzLcQHvhLMr3BIZGwJcZPi9eDPzXWeyn\naVL1eKMqkiRpkthjlySpIwZ2SZI6YmCXJKkjBnZJkjoysT8qcPDBB9fq1auXuhjSsnfjjTd+papW\nLXU5dse6LM3ObOvyxAb21atXs3nz5qUuhrTsJZn+tMBlxboszc5s67JD8ZIkdcTALklSRwzskiR1\nxMAuSVJHDOySJHXEwC5JUkcM7JIkdcTALklSRwzskiR1ZGKfPKfFtfqMK+flOHee84p5OY40KWZT\nd6wXmk/22CVJ6oiBXZKkjuwxsCe5MMl9ST4/kvY7Sb6Q5LNJ/jLJASPbzkyyJcltSU4cST+ppW1J\ncsZI+pFJrm/pf5pkv/m8QEmSVpLZ9NgvAk6alrYJeEFV/Tvg74EzAZIcBZwKPL/t84dJ9kmyD/Bu\n4GTgKOA1LS/AO4Bzq+o5wAPAaWNdkSRJK9geA3tVfRzYOS3tb6pqV1u9DjisLa8DLq2qR6vqi8AW\n4Oj2t6Wq7qiqfwYuBdYlCfAS4PK2/8XAKWNekyRJK9Z8zLH/B+Cv2/KhwN0j27a2tN2lPwN4cKSR\nMJU+oyQbkmxOsnnHjh3zUHRpZXFqTerfWIE9ya8Cu4D3z09xHl9VnV9Va6tq7apVqxbjlFJvLsKp\nNalrcw7sSV4PvBL4uaqqlrwNOHwk22EtbXfp9wMHJNl3WrqkBeDUmtS/OQX2JCcBbwF+uqoeGdm0\nETg1yXclORJYA3wKuAFY04bp9mPoBWxsDYKPAq9q+68HrpjbpUiaB4sytea0mrRwZvN1tw8Cfwc8\nN8nWJKcB7wL2BzYluSnJ/wGoqpuBy4BbgA8Dp1fVN1pFfyNwNXArcFnLC/BW4E1JtjB8MFwwr1co\naVYWc2rNaTVp4ezxkbJV9ZoZkncbfKvqbODsGdKvAq6aIf0OhqE9SUtkZGrt+FlMrbGb9G9NrbXG\nvFNr0hLwWfGat+fAazKNTK29eIaptQ8keSfwLL49tRba1BpD4D4VeG1VVZKpqbVLcWpNWhI+UlZa\nQZxak/pnj11aQZxak/pnj12SpI4Y2CVJ6ohD8ZI0B950quXKHrskSR2xxy5JS2w2vf87z3nFIpRE\nPbDHLklSR+yxa1HNdl7S3okkzY2BXZK0YJxmWHwOxUuS1BF77JKkOfErf8uTPXZJkjpiYJckqSMG\ndkmSOuIcuyRpSfk12Pllj12SpI4Y2CVJ6oiBXZKkjhjYJUnqiIFdkqSOGNglSeqIgV2SpI7sMbAn\nuTDJfUk+P5J2UJJNSW5vrwe29CQ5L8mWJJ9N8qKRfda3/LcnWT+S/oNJPtf2OS9J5vsiJUlaKWbz\ngJqLgHcBl4yknQFcU1XnJDmjrb8VOBlY0/6OAd4DHJPkIOAsYC1QwI1JNlbVAy3PfwKuB64CTgL+\nevxLkyTNlT/wMrn22GOvqo8DO6clrwMubssXA6eMpF9Sg+uAA5I8EzgR2FRVO1sw3wSc1LY9raqu\nq6piaDycgiRJmpO5zrEfUlXb2/I9wCFt+VDg7pF8W1va46VvnSF9Rkk2JNmcZPOOHTvmWHRp5XJq\nTerf2DfPtZ52zUNZZnOu86tqbVWtXbVq1WKcUurNRQzTXaOmptbWANe0dXjs1NoGhmkzRqbWjgGO\nBs6aagzw7am1qf2mn0vSAptrYL+3DaPTXu9r6duAw0fyHdbSHi/9sBnSJS0Ap9ak/s01sG8Epobf\n1gNXjKS/rg3hHQs81IbsrwZOSHJga9mfAFzdtj2c5Ng2ZPe6kWNJWhyLPrXmtJq0cGbzdbcPAn8H\nPDfJ1iSnAecAL0tyO/DStg7DXe13AFuA9wK/AFBVO4G3Aze0v99oabQ8f9T2+Qe8I15aMos1tea0\nmrRw9vh1t6p6zW42HT9D3gJO381xLgQunCF9M/CCPZVD0oK5N8kzq2r7XkytHTct/VqcWpOWBZ88\nJ8mpNakjs3lAjaROtKm144CDk2xluLv9HOCyNs12F/Dqlv0q4OUM02SPAG+AYWotydTUGnzn1NpF\nwJMYptWcWltmfPBM/wzs0gri1JrUP4fiJUnqiD12SZoAsxlCv/OcVyxCSbTc2WOXJKkjBnZJkjpi\nYJckqSPOsS8y58kkSQvJwN4xv68qrSy913k7RrPjULwkSR0xsEuS1BEDuyRJHXGOXcuSc2mSNDf2\n2CVJ6oiBXZKkjhjYJUnqiIFdkqSOGNglSeqIgV2SpI4Y2CVJ6oiBXZKkjviAmmXIh7NIkubKHrsk\nSR2xxy5J0/T+86fq21g99iT/PcnNST6f5INJvjvJkUmuT7IlyZ8m2a/l/a62vqVtXz1ynDNb+m1J\nThzvkiRJWrnmHNiTHAr8N2BtVb0A2Ac4FXgHcG5VPQd4ADit7XIa8EBLP7flI8lRbb/nAycBf5hk\nn7mWS5KklWzcOfZ9gScl2Rd4MrAdeAlwedt+MXBKW17X1mnbj0+Sln5pVT1aVV8EtgBHj1kuSXvJ\nETipD3MO7FW1Dfhd4EsMAf0h4Ebgwara1bJtBQ5ty4cCd7d9d7X8zxhNn2Gfx0iyIcnmJJt37Ngx\n16JLmsYROKkf4wzFH8jQ2z4SeBbwFIaKvGCq6vyqWltVa1etWrWQp5JWIkfgpA6Mc1f8S4EvVtUO\ngCR/AfwocECSfVuv/DBgW8u/DTgc2No+OJ4O3D+SPmV0H+2Gd+1qPlXVtiRTI3BfB/6GvRiBSzI6\nAnfdyKFnHIFLsgHYAHDEEUfM+/VIK9k4c+xfAo5N8uTWUj8euAX4KPCqlmc9cEVb3tjWads/UlXV\n0k9tc3ZHAmuAT41RLkl7abFH4Bx9kxbOnHvsVXV9ksuBTwO7gM8A5wNXApcm+c2WdkHb5QLgfUm2\nADsZ5uGoqpuTXMbQKNgFnF5V35hruSTNiSNw6oJP7hzzATVVdRZw1rTkO5hhTq2q/gn4md0c52zg\n7HHKImks3xqBYxiKPx7YzLdH4C5l5hG4v2NkBC7JRuADSd7J0PN3BE5aZD55TpIjcFJHDOySAEfg\npF74IzCSJHXEwC5JUkcM7JIkdcTALklSR7x5bh75NDhJ0lKzxy5JUkfssWti+YQpSfpO9tglSeqI\ngV2SpI4Y2CVJ6oiBXZKkjhjYJUnqiIFdkqSOGNglSeqIgV2SpI4Y2CVJ6oiBXZKkjhjYJUnqiM+K\nlyStKL3/zoQ9dkmSOmJglySpIwZ2SZI6MlZgT3JAksuTfCHJrUl+OMlBSTYlub29HtjyJsl5SbYk\n+WySF40cZ33Lf3uS9eNelCRJK9W4PfY/AD5cVc8Dvh+4FTgDuKaq1gDXtHWAk4E17W8D8B6AJAcB\nZwHHAEcDZ001BiRJ0t6Zc2BP8nTgJ4ALAKrqn6vqQWAdcHHLdjFwSlteB1xSg+uAA5I8EzgR2FRV\nO6vqAWATcNJcyyVpbhyBk/owTo/9SGAH8MdJPpPkj5I8BTikqra3PPcAh7TlQ4G7R/bf2tJ2l/4d\nkmxIsjnJ5h07doxRdEkzcARO6sA4gX1f4EXAe6rqB4Cv8e1KD0BVFVBjnOMxqur8qlpbVWtXrVo1\nX4eVVjxH4KR+jBPYtwJbq+r6tn45Q6C/t1Vw2ut9bfs24PCR/Q9rabtLl7R4FnUEztE3aeHMObBX\n1T3A3Ume25KOB24BNgJT82rrgSva8kbgdW1u7ljgofaBcTVwQpID25DdCS1N0uJZ1BE4R9+khTPu\nI2V/EXh/kv2AO4A3MDQWLktyGnAX8OqW9yrg5cAW4JGWl6rameTtwA0t329U1c4xyyVp78w0AncG\nbQSuqrbvxQjccdPSr13AckuaZqzAXlU3AWtn2HT8DHkLOH03x7kQuHCcskiau6q6J8ndSZ5bVbfx\n7RG4WxhG3s7hO0fg3pjkUoYb5R5qwf9q4LdGbpg7AThzMa9FWun8ERhJUxyBkzpgYFfXev8Vp/nk\nCJzUB58VL0lSRwzskiR1xKF4SZKmmeRpPHvskiR1xMAuSVJHDOySJHXEwC5JUkcM7JIkdcTALklS\nRwzskiR1xMAuSVJHDOySJHXEwC5JUkcM7JIkdcTALklSRwzskiR1xMAuSVJHDOySJHXEwC5JUkf2\nXeoCSJI0iVafceWs8t15zisWuCSPZY9dkqSOGNglSeqIQ/Fa8WYznLbYQ2mSNFdj99iT7JPkM0k+\n1NaPTHJ9ki1J/jTJfi39u9r6lrZ99cgxzmzptyU5cdwySZK0Us3HUPwvAbeOrL8DOLeqngM8AJzW\n0k8DHmjp57Z8JDkKOBV4PnAS8IdJ9pmHcknaSzbUpck3VmBPchjwCuCP2nqAlwCXtywXA6e05XVt\nnbb9+JZ/HXBpVT1aVV8EtgBHj1MuSXNmQ12acOP22H8feAvwzbb+DODBqtrV1rcCh7blQ4G7Adr2\nh1r+b6XPsM9jJNmQZHOSzTt27Biz6JJG2VCX+jDnm+eSvBK4r6puTHLc/BVp96rqfOB8gLVr19Zi\nnFOC5ft91Xk21VDfv63PuqGeZLShft3IMWdsqCfZAGwAOOKII+b3KqQVbpwe+48CP53kTuBShpb9\nHwAHJJlqMBwGbGvL24DDAdr2pwP3j6bPsI+kRTDaUF+M81XV+VW1tqrWrlq1ajFOKa0Ycw7sVXVm\nVR1WVasZ5tQ+UlU/B3wUeFXLth64oi1vbOu07R+pqmrpp7abcY4E1gCfmmu5JM2JDXWpEwvxgJq3\nAm9KsoVhaO6Cln4B8IyW/ibgDICquhm4DLgF+DBwelV9YwHKJWk3bKhL/ZiXB9RU1bXAtW35Dma4\nWaaq/gn4md3sfzZw9nyURdK8eitwaZLfBD7DYxvq72sN9Z0MjQGq6uYkUw31XdhQlxadT56T9Bi9\nN9RneyOkNF8W++mWPitekqSOGNglSeqIgV2SpI4Y2CVJ6oiBXZKkjhjYJUnqiIFdkqSO+D32WfB7\nr5KkSWGPXZKkjhjYJUnqiIFdkqSOGNglSeqIgV2SpI54V7y0yBb7l54krSz22CVJ6oiBXZKkjjgU\nL80jH2YkaanZY5ckqSP22KVlyBvsJM2VPXZJkjpiYJckqSMGdkmSOmJglySpI3MO7EkOT/LRJLck\nuTnJL7X0g5JsSnJ7ez2wpSfJeUm2JPlskheNHGt9y397kvXjX5YkSSvTOD32XcCbq+oo4Fjg9CRH\nAWcA11TVGuCatg5wMrCm/W0A3gNDQwA4CzgGOBo4a6oxIGlx2FCX+jHnwF5V26vq0235q8CtwKHA\nOuDilu1i4JS2vA64pAbXAQckeSZwIrCpqnZW1QPAJuCkuZZL0pzYUJc6MS9z7ElWAz8AXA8cUlXb\n26Z7gEPa8qHA3SO7bW1pu0uf6TwbkmxOsnnHjh3zUXRJ2FCXejJ2YE/yVODPgV+uqodHt1VVATXu\nOUaOd35Vra2qtatWrZqvw0oasRgNdRvp0sIZK7AneSJDUH9/Vf1FS763tdxpr/e19G3A4SO7H9bS\ndpcuaZEtVkPdRrq0cMa5Kz7ABcCtVfXOkU0bgakbZtYDV4ykv67ddHMs8FDrCVwNnJDkwDYXd0JL\nk7SIbKhLfRinx/6jwM8DL0lyU/t7OXAO8LIktwMvbesAVwF3AFuA9wK/AFBVO4G3Aze0v99oaZIW\niQ11qR9z/hGYqvokkN1sPn6G/AWcvptjXQhcONeySBrbVEP9c0luamm/wtAwvyzJacBdwKvbtquA\nlzM01B8B3gBDQz3JVEMdbKhLi85fd5NkQ13qiI+UlSSpIwZ2SZI6YmCXJKkjBnZJkjpiYJckqSMG\ndkmSOmJglySpIwZ2SZI6YmCXJKkjBnZJkjpiYJckqSMGdkmSOmJglySpIwZ2SZI6YmCXJKkjBnZJ\nkjpiYJckqSP7LnUBJGm+rD7jyqUugrTk7LFLktSRFd9jt4UvSeqJPXZJkjpiYJckqSMGdkmSOmJg\nlySpI8smsCc5KcltSbYkOWOpyyNp7qzP0tJZFnfFJ9kHeDfwMmArcEOSjVV1yzjH9Y53afEtRH22\nLkuzt1x67EcDW6rqjqr6Z+BSYN0Sl0nS3FifpSW0LHrswKHA3SPrW4FjpmdKsgHY0Fb/Mclti1C2\nvXUw8JWlLsSYJv0aJr38MItryDtmfazvGbcwe2mP9XlC6jJM/v+lSS8/TP41zKr8s6zPs6rLyyWw\nz0pVnQ+cv9TleDxJNlfV2qUuxzgm/RomvfzQxzU8nkmoyzD578Oklx8m/xqWovzLZSh+G3D4yPph\nLU3S5LE+S0touQT2G4A1SY5Msh9wKrBxicskaW6sz9ISWhZD8VW1K8kbgauBfYALq+rmJS7WXC37\n4cVZmPRrmPTywwRfg/V5WZn08sPkX8Oilz9VtdjnlCRJC2S5DMVLkqR5YGCXJKkjBvZ5lOTOJJ9L\nclOSzUtdnj1JcmGS+5J8fiTtoCSbktzeXg9cyjLuyW6u4W1JtrX34aYkL1/KMj6eJIcn+WiSW5Lc\nnOSXWvpEvQ+9mbS6DJNfnye9LsPyqc8G9vn3k1X1wgn53uVFwEnT0s4ArqmqNcA1bX05u4jvvAaA\nc9v78MKqumqRy7Q3dgFvrqqjgGOB05McxeS9Dz2apLoMk1+fL2Ky6zIsk/psYF/BqurjwM5pyeuA\ni9vyxcApi1qovbSba5gYVbW9qj7dlr8K3Mrw5LaJeh+09Ca9Pk96XYblU58N7POrgL9JcmN7ZOYk\nOqSqtrfle4BDlrIwY3hjks+24b1lO/w4Kslq4AeA6+nnfZhUPdRl6OP/0cTVZVja+mxgn18/VlUv\nAk5mGIL5iaUu0Dhq+C7kJH4f8j3A9wIvBLYDv7e0xdmzJE8F/hz45ap6eHTbBL8Pk6yrugwT+/9o\n4uoyLH19NrDPo6ra1l7vA/6S4VeuJs29SZ4J0F7vW+Ly7LWqureqvlFV3wTeyzJ/H5I8keFD4P1V\n9RcteeLfh0nWSV2GCf9/NGl1GZZHfTawz5MkT0my/9QycALw+cffa1naCKxvy+uBK5awLHMyVYGa\nf88yfh+SBLgAuLWq3jmyaeLfh0nVUV2GCf9/NEl1GZZPffbJc/MkybMZWvYwPKr3A1V19hIWaY+S\nfBA4juFnBe8FzgL+H3AZcARwF/Dqqlq2N7Ts5hqOYxi6K+BO4D+PzG8tK0l+DPgE8Dngmy35Vxjm\n5SbmfejJJNZlmPz6POl1GZZPfTawS5LUEYfiJUnqiIFdkqSOGNglSeqIgV2SpI4Y2CVJ6oiBXZKk\njhjYJUnqyP8HQW1Vo3yF368AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f869c32a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[8,4])\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"words\")\n",
    "plt.hist(list(map(len, all_words)), bins=20);\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('translations')\n",
    "plt.hist(list(map(len, all_translations)), bins=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: auxiliary functions\n",
    "\n",
    "we need some helper functions that\n",
    "* convert data from strings to integer matrices\n",
    "* sample random minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_matrix(sequences, token_to_i, max_len=None, PAX_ix=PAD_ix):\n",
    "    \"\"\"\n",
    "    convert variable length token sequences into  fixed size matrix\n",
    "    example usage: \n",
    "    >>>print( as_matrix(words[:3],source_to_ix))\n",
    "    [[15 22 21 28 27 13 -1 -1 -1 -1 -1]\n",
    "     [30 21 15 15 21 14 28 27 13 -1 -1]\n",
    "     [25 37 31 34 21 20 37 21 28 19 13]]\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len, sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences), max_len), dtype='int32') + PAD_ix\n",
    "    for i, seq in enumerate(sequences):\n",
    "        row_ix = list(map(token_to_i.get, seq))[:max_len]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_batch(words, word_to_translation, batch_size):\n",
    "    \"\"\"\n",
    "    sample random batch of words and random correct translation for each word\n",
    "    example usage:\n",
    "    batch_x,batch_y = sample_batch(train_words, word_to_translations,10)\n",
    "    \"\"\"\n",
    "    \n",
    "    #choose words\n",
    "    batch_words = np.random.choice(words, size=batch_size)\n",
    "    \n",
    "    #choose translations\n",
    "    batch_trans_candidates = list(map(word_to_translation.get, batch_words))\n",
    "    batch_trans = list(map(random.choice, batch_trans_candidates))\n",
    "    \n",
    "    return as_matrix(batch_words, source_to_ix), as_matrix(batch_trans, target_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset\n",
    "\n",
    "We hold out 20% of all words to be used for validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_words, test_words = train_test_split(all_words, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build encoder-decoder (1 point)\n",
    "\n",
    "__assignment starts here__\n",
    "\n",
    "Our architecture consists of two main blocks:\n",
    "* Encoder reads words character by character and outputs code vector (usually a function of last RNN state)\n",
    "* Decoder takes that code vector and produces translations character by character\n",
    "\n",
    "In this section, we'll implement __encoder__ the same way you did for week6.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cpu, floatX=float32\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=cpu, floatX=float32\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more note: in this assignment, we'll be using classes as namespaces:\n",
    "\n",
    "```\n",
    "class my_pocket:\n",
    "    coin = \"$\"\n",
    "    coins = coin*3\n",
    "    mobile = \"nokia 3310\"\n",
    "    \n",
    ">>>print my_pocket.coins\n",
    "$$$\n",
    ">>>print my_pocket.mobile\n",
    "nokia 3310\n",
    "```\n",
    "\n",
    "\n",
    "Your first assignment is to implement encoder network using lasagne layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_by_eos(is_eos):\n",
    "    \"\"\"takes indicator of \"it ends now\", returns mask.\n",
    "    Ignores everything after first end.\"\"\"\n",
    "    assert is_eos.ndim == 2\n",
    "    is_right_after_eos = T.concatenate([T.zeros_like(is_eos[:,:1]), is_eos[:,:-1]], -1)\n",
    "    is_after_eos = T.eq(T.cumsum(is_right_after_eos, axis=-1), 0).astype('uint8')\n",
    "    return is_after_eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder:\n",
    "    \"\"\"encoder rnn\"\"\"\n",
    "    \n",
    "    #input tokens and mask\n",
    "    input_sequence = T.matrix('token sequence', 'int32')\n",
    "    input_mask = get_mask_by_eos(T.eq(input_sequence, EOS_ix_source))\n",
    "    \n",
    "    inp = InputLayer(shape=(None, None), input_var=input_sequence, name='encoder input')\n",
    "    inp_mask = InputLayer(shape=(None, None), input_var=input_mask, name='encoder input mask')\n",
    "    \n",
    "    #embedding\n",
    "    emb = EmbeddingLayer(inp,\n",
    "                         input_size=len(source_letters),\n",
    "                         output_size=50)\n",
    "    \n",
    "    #encoder rnn\n",
    "    rnn = GRULayer(incoming=emb,\n",
    "                   num_units=512,\n",
    "                   mask_input=inp_mask)\n",
    "    \n",
    "    #slice last time-step of encoder rnn\n",
    "    rnn_last = SliceLayer(rnn, -1, axis=1, name='last rnn time-step')\n",
    "    \n",
    "    #compute decoder initial state\n",
    "    code = DenseLayer(rnn_last, 512, nonlinearity=T.tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder\n",
    "\n",
    "In this section, we will define __one step__ of decoder (just like we defined one step of agent last week).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentnet.memory import RNNCell, GRUCell, LSTMCell\n",
    "from agentnet.resolver import ProbabilisticResolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder:\n",
    "    \"\"\"single step of decoder rnn\"\"\"\n",
    "    \n",
    "    inp = InputLayer((None,), name=\"prev phoneme\")\n",
    "    \n",
    "    emb = EmbeddingLayer(inp, len(target_letters), 50)\n",
    "    \n",
    "    #decoder memory\n",
    "    prev_gru = InputLayer((None, 512))\n",
    "    \n",
    "    gru = GRUCell(prev_gru, emb) #use shift-tab to figure out what goes here\n",
    "    \n",
    "    logits = DenseLayer(gru, len(target_letters), nonlinearity=None)\n",
    "    \n",
    "    #probabilities\n",
    "    probs = NonlinearityLayer(logits, T.nnet.softmax)\n",
    "    \n",
    "    #output phonemes\n",
    "    out = ProbabilisticResolver(probs, assume_normalized=True)\n",
    "    \n",
    "    #log-probabilities\n",
    "    logprobs = NonlinearityLayer(logits, T.nnet.logsoftmax)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wire it all together (1 point)\n",
    "\n",
    "Here we define functions for model _inference_ (both greedy and sampled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentnet import Recurrence\n",
    "from collections import OrderedDict as od\n",
    "class model:\n",
    "    #maximum output length for inference\n",
    "    n_steps = theano.shared(MAX_OUTPUT_LENGTH)\n",
    "    \n",
    "    #initial inputs: indices of \"START\" special phoneme.\n",
    "    l_start = InputLayer((None,), T.zeros_like(encoder.input_sequence[:, 0])+BOS_ix_target)\n",
    "\n",
    "    #Here we define recurrence: it's a custom recurrent layer, acting exactly like Agent, \n",
    "    #except it's a lasagne layer.\n",
    "    \n",
    "    rec = Recurrence(\n",
    "        #recurrent states\n",
    "        state_variables=od({decoder.gru: decoder.prev_gru,\n",
    "                            decoder.out: decoder.inp}),\n",
    "        \n",
    "        #initial values for recurrent states\n",
    "        state_init={decoder.gru: encoder.code,\n",
    "                    decoder.out: l_start},\n",
    "        \n",
    "        tracked_outputs=(decoder.out, decoder.probs, decoder.logprobs),\n",
    "        unroll_scan=False,\n",
    "        n_steps=n_steps\n",
    "    )\n",
    "    \n",
    "    weights = get_all_params(rec, trainable=True)\n",
    "    \n",
    "    \n",
    "    #sample mode\n",
    "    predicted_translations, probs_seq, logprobs_seq = get_output(rec[decoder.out, decoder.probs, decoder.logprobs])\n",
    "    auto_updates = rec.get_automatic_updates()\n",
    "\n",
    "    #output mask\n",
    "    mask = get_mask_by_eos(T.eq(predicted_translations, EOS_ix_target))\n",
    "    \n",
    "    generate_sample = theano.function([encoder.input_sequence],\n",
    "                                      predicted_translations,\n",
    "                                      updates=auto_updates)\n",
    "    \n",
    "    #greedy mode (picking max-probability actions on each step)\n",
    "    greedy_translations = get_output(rec[decoder.out], recurrence_flags={\"greedy\": True})\n",
    "    greedy_auto_updates = rec.get_automatic_updates()\n",
    "    \n",
    "    greedy_mask = get_mask_by_eos(T.eq(greedy_translations, EOS_ix_target))\n",
    "    \n",
    "    \n",
    "    generate_greedy = theano.function([encoder.input_sequence],\n",
    "                                      greedy_translations,\n",
    "                                      updates=greedy_auto_updates)\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def translate(word, sample=False):\n",
    "        assert word.endswith(END)\n",
    "        \n",
    "        #convert to matrix\n",
    "        word_ix = as_matrix([word.lower()], source_to_ix)\n",
    "        \n",
    "        #generate output\n",
    "        if sample:\n",
    "            trans_ix = model.generate_sample(word_ix)[0]\n",
    "        else:\n",
    "            trans_ix = model.generate_greedy(word_ix)[0]\n",
    "        \n",
    "        #convert from int32 to string\n",
    "        trans = list(map(target_letters.__getitem__, trans_ix))\n",
    "        \n",
    "        #crop padding\n",
    "        if END in trans:\n",
    "            trans = trans[:trans.index(END)+1]\n",
    "            \n",
    "        return ''.join(trans)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:עור בהיר;\n",
      "y_sampled:あקコ門ñńلòÿmנá チ+ảярŭ$\n",
      "y_greedy:سسسòכòńńʻה/ć+@יəəäöư\n"
     ]
    }
   ],
   "source": [
    "#test untrained model\n",
    "#should be random\n",
    "print('x:' + all_words[0])\n",
    "print('y_sampled:' + model.translate(all_words[0], sample=True))\n",
    "print('y_greedy:' + model.translate(all_words[0]))\n",
    "\n",
    "#praise Cthulhu!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring function\n",
    "\n",
    "LogLikelihood is a poor estimator of model performance.\n",
    "* If we predict zero probability once, it shouldn't ruin entire model.\n",
    "* It is enough to learn just one translation if there are several correct ones.\n",
    "* What matters is which output will we produce if we __take most likely phoneme on each step.__\n",
    "\n",
    "Therefore, we will use minimal Levenshtein distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance #!pip install editdistance\n",
    "\n",
    "def get_distance(word, trans):\n",
    "    \"\"\"\n",
    "    A function that takes word and predicted translation\n",
    "    and evaluates (Levenshtein's) edit distance to closest correct translation\n",
    "    \"\"\"\n",
    "    references = word_to_translation[word]\n",
    "    assert len(references)!=0, \"wrong/unknown word\"\n",
    "    return min(editdistance.eval(trans, ref) for ref in references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(bsize=100):\n",
    "    \"\"\"a function that computes levenshtein distance for bsize random samples\"\"\"\n",
    "    \n",
    "    batch_words = np.random.choice(test_words, size=bsize)\n",
    "    \n",
    "    trans = [model.translate(word, sample=False) for word in batch_words]\n",
    "    distances = [get_distance(word, tran) for word, tran in zip(batch_words, trans)]\n",
    "    \n",
    "    return np.array(distances, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.889999,\n",
       " 19.77,\n",
       " 19.74,\n",
       " 19.799999,\n",
       " 19.85,\n",
       " 19.860001,\n",
       " 19.83,\n",
       " 19.780001,\n",
       " 19.799999,\n",
       " 19.719999]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#should be around 5-50 and decrease rapidly :)\n",
    "[score(100).mean() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Supervised pre-training\n",
    "\n",
    "Here we define a function that trains our model through maximizing log-likelihood a.k.a. minimizing crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    }
   ],
   "source": [
    "from agentnet.learning.generic import get_values_for_actions\n",
    "\n",
    "class llh_trainer:\n",
    "\n",
    "    #variable for correct answers\n",
    "    reference_answers = T.imatrix(\"reference translations\")\n",
    "    \n",
    "    #shift 1 step to the past to get \"previous answers\"\n",
    "    prev_answers = T.concatenate([T.zeros_like(reference_answers[:,:1])+BOS_ix_target,\n",
    "                                  reference_answers[:,:-1]], axis=1)\n",
    "    \n",
    "    #mask on prev answers\n",
    "    input_mask = get_mask_by_eos(T.eq(prev_answers, EOS_ix_target))\n",
    "    \n",
    "    #create input layers\n",
    "    l_sequence = InputLayer((None, None), prev_answers)\n",
    "    l_mask = InputLayer((None, None), input_mask)\n",
    "    \n",
    "    #teacher-forced trainer\n",
    "    rec = Recurrence(state_variables=od({decoder.gru: decoder.prev_gru}),\n",
    "                     input_sequences={decoder.inp: l_sequence},\n",
    "                     state_init={decoder.gru: encoder.code},\n",
    "                     tracked_outputs=(decoder.probs, decoder.logprobs),\n",
    "                     unroll_scan=False,\n",
    "                     mask_input=l_mask)\n",
    "    \n",
    "    \n",
    "    #get log-probabilities\n",
    "    logprobs_seq = get_output(rec[decoder.logprobs])\n",
    "    auto_updates = rec.get_automatic_updates()\n",
    "    \n",
    "    #compute mean crossentropy\n",
    "    crossentropy = -get_values_for_actions(logprobs_seq, reference_answers)\n",
    "    \n",
    "    loss = T.sum(crossentropy*input_mask)/T.sum(input_mask)\n",
    "    \n",
    "    #get all params\n",
    "    weights = get_all_params(rec, trainable=True)\n",
    "\n",
    "    #weight updates                 \n",
    "    updates = lasagne.updates.adam(loss, weights, learning_rate=0.001)\n",
    "    \n",
    "    train_step = theano.function([encoder.input_sequence, reference_answers],\n",
    "                                 loss,\n",
    "                                 updates=auto_updates+updates)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAEICAYAAAByPazKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8HPWd//HXR81yr5LcexEdgzDVIMt0CIQc4UISDgjG\nRwK55C7lx+XuklxyhVyuEpJwBhsILSGFQAIJ+CzLhRiwDAbbuMtytyX3Kqt9fn/sOFnEqlhaaba8\nn4/HPjQ7852Zz6529rPzne98v+buiIiISOLLCDsAERERaRslbRERkSShpC0iIpIklLRFRESShJK2\niIhIklDSFhERSRJK2l3EzIrNbFvYcbSXmd1lZoujnh8xs7Fx2vY3zOzxYHq0mbmZZcVp2yODWDPj\nsT1JD8l+vIbBzFaZWXEX7etRM/uHrthXolHSlnZx917uXtFSmbZ+8bn7v7j7jHjEZWaVZnZl1La3\nBLE2xGP7IonMzNaa2cQY88vMLC7HWHPc/Qx3L4v3dpueMAT7us/dvxvvfSUDJe00EK+z1s6QyLGJ\nhKG9x4SZjQMy3X1dV+1Tup6S9ikws/9nZr9oMu9/zOzhYPpuM1ttZofNrMLM/rKN2zUz+y8zqzKz\nQ2a2wszODJZ1N7P/MLPNZnbQzBabWfdg2U1BldSB4Jf0aVHbrAzifR84amZZZjbUzH5pZtVmtsnM\n/qqFmAaa2ctBPG8D45osdzMbH0xfb2YfBK97u5l91cx6Ar8DhgbV00eC/X/bzH5hZs+Y2SHgrmDe\nM01C+JyZ7TCznWb21aj9Pmlm/xT1/I9n82b2NDAS+E2wv683rW4PYnjZzPaZ2QYzuzdqW982sxfM\n7CfBa1llZkVt+R9K4kmn4zVwA/BqjHj/GZgKPBIcF48E893M7jez9cD6qPdna/C6lpnZ1KjttHh8\nWFQtVxvKnmdm7wbLfm5mP4s+rqPKnQY8ClwcxH4gmP/H74GT3wHB8V4VfGd8PPheWhcc69+I2maG\nmT1oZhvNbG8Q54BW3tvE4e56tPEBjAKOAb2D55nATuCi4PkNRJKbAVcEZc8LlhUD25rZ7jXAMqBf\nsO5pwJBg2Q+BMmBYsL9LgG7AROAocBWQDXwd2ADkBOtVAsuBEUB3Ij/QlgHfBHKAsUAFcE0zMf0U\neAHoCZwJbAcWRy13YHwwvROYGkz3b+k1A98G6oCPBzF1D+Y9EywfHWz7+WDfZwHVwJXB8ieBf4ra\n3of2EbzuK6Oen9xeVvB8IfAjIBc4N9h2SVRsNcD1wXv9r8CbYX/u9NDx2trxGmzj9y0cz2XAjCbz\nHJgLDAC6B/M+CwwEsoCvALuA3GBZi8dH9LHXUtng9WwGvhS8F58Aaok6rpvEeRdR3z3BvCdPlg/+\nV/XBe5UN3Bsc188BvYEzgOPAmKD8l4A3geHB/+Z/gefD/ry2+XMddgDJ9gAWA38RTF8FbGyh7K+B\nL0V9sJr7EigB1gEXARlR8zOCD9s5Mdb5B+CFJmW3A8XB80rgc1HLLwS2NNnG3wJPxNh2JpHEWhg1\n719oPmlvAf4S6NNkOx95zcHBvDDGvKZJO3rf/wbMDqb/eLDG2gctJG0iX4gNBF/iwfJ/BZ6MiuP/\nopadDhwP+zOnR/sf6XC8Bst6AHuBbs0sLyN20i5p5f3bf/L1tHZ88NGkHbMscHnw2q3J/6kjSfs4\nkUsDEEnUDlwYVX4Z8PFgejUwPWrZECLfd1lhf17b8lD1+Kl7Drg9mP508BwAM7vOzN4MqmMOEPmV\nOai1Dbp7KfAIkV/pVWY2y8z6BOvmAhtjrDaUyK/Vk9toBLYS+YV/0tao6VFEqqoPnHwA3wAKYmw7\nj0iSi15/c4xyJ/0Zkde62cwWmNnFLZRtGldbymwm8no7aiiwz90PN9l29Hu2K2r6GJBrut6XzNLh\neAWYDvzB3U+0Fn8THzoWLXJpa3VQtX8A6MuH35NTOT6aKzsU2O5BxowVRzvs9T81Nj0e/N0dtfw4\n0CuYHgW8GPW+ribyY7659zahKGmfup8DxWY2HLiF4EvAzLoBvwT+HShw935Eri9ZWzbq7g+7+/lE\nfpFOBL4G7CFSxTQuxio7iHz4CPZvRM4kt0dvNmp6K7DJ3ftFPXq7+/Uxtl1NpLppRNS8kS3EvtTd\nbwbyiZytvBBj/x9apbltRWm67x3B9FEiZxUnDT6Fbe8ABphZ7ybb3t5MeUl+6XC8QuQHx0euZzez\n7Zjzg+vXXwduA/oH78lB2vienIKdwLDgPThpRHOFadv3xanYClzX5L3Ndfek+B5Q0j5F7l5NpKrp\nCSIH1epgUQ6R6yPVQL2ZXQdc3ZZtmtkFZnahmWUTSUo1QGPwa3wO8J9Bo5RMM7s4+MJ5AbjBzKYH\n630FOAH8oZndvA0cDhq7dA+2daaZXRDjNTYAvwK+bWY9zOx04M5mYs8xs8+YWV93rwMOAY3B4t3A\nQDPr25b3oYl/CPZ9BnA38LNg/nLgejMbYGaDgS83WW83ket/H+HuW4m8P/9qZrlmdjZwD9C0EZyk\niHQ4XgPXAa+0EHazx0WU3kR+rFcDWWb2TaBPK+u0xxIiZ7YPWKTB3c3AlBbK7waGm1lOnPb/KPDP\nZjYKwMzyghiSgpJ2+zwHXElUVVtQ5fpXRA7O/USq4l5u4/b6AI8F620mcm3q+8GyrwIrgKXAPuB7\nRK6jrSXSaOQHRH7hfwz4mLvXxtpBkIhvJNL4alOwzuNEqr9ieYBIddIuItePnmgh/juASou0Br8P\n+EywzzVEGpRVBFVRp1LFvYBIQ515wL+7++vB/KeB94hcP3udPyXzk/4V+Ptgf1/lo24ncp17B/Ai\n8C13/79TiEuST0ofrxZpuX7E3be0EPP/ALea2X4LWs/H8BqRxmzrgtdVQ8errT8ieM2fIPKD+QCR\n9+W3RH7ExFIKrAJ2mdmeOITwP0T+16+b2WEijdIujMN2u4R9+LKCiIgkEzP7OjDI3b8ediztZWZv\nAY+6e0snB0KksZGIiCSvSuA3YQdxKszsCmAtkRqEzwBnEznLl1YoaYuIJDF3f6H1UglnEn/qB6IC\nuNXdd4YbUnJQ9biIiEiSUEM0ERGRJJGQ1eODBg3y0aNHhx2GSEJbtmzZHnfPCzuOlrTlWD569Cg9\ne/bsmoDiKFnjhuSNPZXjbuvxnJBJe/To0ZSXl4cdhkhCM7OWeqlLCG05lsvKyiguLu6agOIoWeOG\n5I09leNu6/Gs6nEREZEkoaQtIiKSJJS0RUREkoSStoiISJJQ0hYREUkSStoiIiJJotWkbWYjzGy+\nmX1gZqvM7EvB/AFmNtfM1gd/+zez/p1BmfVmFnN4RxEREWldW86064GvuPvpwEXA/cH4yg8C89x9\nApHhEx9suqKZDQC+RWTYsynAt5pL7iIi0rlO1DfwzJubqW1Q99XJqtWk7e473f2dYPowsBoYBtwM\nPBUUewr4eIzVrwHmuvs+d98PzAWujUfgIiJyap5espm///VK3tpZH3Yo0k6n1COamY0GJgNvAQVR\no7LsAgpirDKMDw+ivi2YF2vbM4GZACNHjjyVsKQLjH7wlVbLVD50QxdEIiLtUVPXwKyFFQC8V90Q\ncjTSXm1uiGZmvYBfAl9290PRyzwyVFiH6lvcfZa7F7l7UV5eQnenLCKSdH6+bBtVh09QOLg3K/c0\nUFvfGHZI0g5tStpmlk0kYT/r7r8KZu82syHB8iFAVYxVtwMjop4PD+aJiEgXqWto5NGyjZw3sh9/\nc9VEahqgvHJf2GFJO7Sl9bgBs4HV7v6fUYteBk62Br8TeCnG6q8BV5tZ/6AB2tXBPBER6SIvvrud\n7QeO88WSCVw6fhBZGTBvTazzLEl0bTnTvhS4Aygxs+XB43rgIeAqM1sPXBk8x8yKzOxxAHffB3wX\nWBo8vhPMExGRLtDQ6Pxo/gbOHNaH4kl59OyWReGATOYraSelVhuiuftiwJpZPD1G+XJgRtTzOcCc\n9gYoIiLt99v3d1C59xiPfvZ8IhWncE5eJs+uPsqmPUcZMyj5xqdOZ+oRTUQkRTU2Oo+UbmBiQS+u\nPv1PN/ick5cJQKnOtpOOkraISIp6/YNdrK86wv3TxpOR8acK0/weGYzP76Uq8iSkpC0ikoLcnR+U\nbmDMoJ7cePbQjyyfXpjPW5v2cuSEOlpJJkraIiIpqGxtNat2HOLzxePIzPhos6RphfnUNTiL11eH\nEJ20l5K2iEiKcXceLl3PsH7duWVyzE4oOX9Uf3rnZum6dpJR0hYRSTFLNu7l3S0HuK94HNmZsb/m\nszMzuGJiHqVrqmls1AAiyUJJW0QkxfygdAMFfbrxyfOHt1iupDCfPUdOsHLHwS6KTDpKSVtEJIWU\nV+5jScVeZl4+jtzszBbLXjExDzPd+pVMlLRFRFLID0o3MLBnDrdPGdFq2YG9ujF5RD8l7SSipC0i\nkiLe33aABeuquWfqGHrktG3k5ZLCfN7fdpCqwzWdHJ3Eg5K2iEiKeKR0A31ys7jjolFtXqekMNJT\nWtla3fqVDJS0RURSwJpdh3j9g93cfekYeudmt3m904b0ZkjfXEpXq4o8GShpi6QRM5tjZlVmtjJq\n3gAzm2tm64O//ZtZtyFqpL+Xuy5qaYsfzt9Iz5xM7r509CmtZ2YUT8pn8YY91NY3dk5wEjdK2iLp\n5Ung2ibzHgTmufsEYF7wPJbj7n5u8LipE2OUU7Sx+gi/fX8Hd1w8mn49ck55/emF+Rw5Uc/SSo2c\nnOiUtEXSiLsvBJp+M98MPBVMPwV8vEuDkg77cdlGumVlMGPqmHatf8n4geRkZTBPVeQJr23NC0Uk\nlRW4+85gehdQ0Ey5XDMrB+qBh9z917EKmdlMYCZAQUEBZWVlLe78yJEjrZZJRIkSd/WxRn71znGu\nHJnFyvIlbVonVuyT+hmvvFvJ5b0TN3Enynt+quIZd6tJ28zmADcCVe5+ZjDvZ8CkoEg/4IC7nxtj\n3UrgMNAA1Lt7UVyiFpFO4e5uZs31aTnK3beb2Vig1MxWuPvGGNuYBcwCKCoq8uLi4hb3WVZWRmtl\nElGixP2NF1eQlbGN73z6Cgb3zW3TOrFi39Ktkm++tIqRZxQxNq9X/AONg0R5z09VPONuS/X4kzS5\nBubuf37y2hbwS+BXLaw/LSirhC2SmHab2RCA4G/MUy133x78rQDKgMldFaDEtvPgcX5Rvo1PFg1v\nc8JuzrRJ+YB6R0t0rSbtZq6BAWBmBtwGPB/nuESk67wM3BlM3wm81LSAmfU3s27B9CDgUuCDLotQ\nYpq1sIIGd+67YlyHtzViQA8mFvRi/lol7UTW0YZoU4Hd7r6+meUOvG5my4LrXCISIjN7HlgCTDKz\nbWZ2D/AQcJWZrQeuDJ5jZkVm9niw6mlAuZm9B8wnck1bSTtE1YdP8PzbW7hl8jBGDOgRl21OK8zn\nrYp9HK6pi8v2JP462hDtdlo+y74suAaWD8w1szXBmftHRDdeGTlyZAfDEpFY3P32ZhZNj1G2HJgR\nTP8BOKsTQ5NTNHvxJk7UN/KF4o6fZZ9UMimf/11QweL1e7jurCFx267ET7vPtM0sC/gE8LPmykRd\nA6sCXgSmtFB2lrsXuXtRXl5ee8MSEUl5B47V8vSSSm48e2hcG42dP6o/fXKzdF07gXWkevxKYI27\nb4u10Mx6mlnvk9PA1cDKWGVFRKTtnnijkqO1DTwwbXxct5uVmcEVk/KZv7aKxsbmbiKQMLWatJu5\nBgbwKZpUjZvZUDN7NXhaACwOroG9Dbzi7r+PX+giIunncE0dT7yxiWvOKGDS4N5x335JYR57jtSy\nYvvBuG9bOq7Va9rNXQNz97tizNsBXB9MVwDndDA+ERGJ8pMlmzlUU88D0yZ0yvavmJhPhsG8NVWc\nM6Jfp+xD2k/dmIqIJIljtfXMXryJ4kl5nDW8b6fsY0DPHCaP7M98XddOSEraIiJJ4rm3trDvaC1f\nLInvteymSgrzWbH9IFWHajp1P3LqlLRFRJJATV0DsxZWcPHYgZw/akCn7qukMNI7mjpaSTxK2iIi\nSeDny7ZRdfhEp59lAxQO7s2Qvrm69SsBKWmLiCS4uoZGHi3byHkj+3HxuIGdvj8zo6Qwn8Xr93Ci\nvqHT9ydtp6QtIpLgXnx3O9sPHOeL0ycQGfKh85UU5nO0toG3N8UcekJCoqQtIpLA6hsa+dH8DZw5\nrA/FE7uut8hLxg2iW1aGqsgTjJK2iEgCe2XFTir3HuOBaV13lg3QPSeTS8YNpHRNFe7qHS1RKGmL\niCSoxkbnkdINTCzoxdWnF3T5/ksK89m89xgVe452+b4lNiVtEZEE9foHu1hfdYT7p40nI6PrzrJP\nmnby1i9VkSeMjg7NKSlg9IOvhB2CiDTh7vygdANjBvXkxrOHhhLD8P49mFTQm3mrq5gxdWwoMciH\n6UxbRCQBla2tZtWOQ3y+eByZIZxlnzStMJ+llfs4VFMXWgzyJ0raIiIJxt15uHQ9w/p155bJw0KN\nZfpp+dQ3OovX7wk1DolQ0hYRSTBLNu7l3S0HuK94HNmZ4X5NTx7Rj77ds5m3Wte1E4GStohIgnm4\ndD0FfbrxyfOHhx0KWZkZXDExjwXrqmhs1K1fYVPSFhFJIEsr9/FmxT5mXj6O3OzMsMMBIlXke47U\n8v72g2GHkvaUtEVEEsgjpRsY2DOH26eMCDuUP7piYh4ZBqWrd4cdStprNWmb2RwzqzKzlVHzvm1m\n281sefC4vpl1rzWztWa2wcwejGfgIiKp5v1tB1iwrpp7po6hR07i3JHbr0cO543sT6mG6gxdW860\nnwSujTH/v9z93ODxatOFZpYJ/BC4DjgduN3MTu9IsCIiqeyR0g30yc3ijotGhR3KR5Scls/K7YfY\nfagm7FDSWqtJ290XAu0Z5mUKsMHdK9y9FvgpcHM7tiMikvLW7DrE6x/s5u5Lx9A7NzvscD6iRL2j\nJYSOXNN+wMzeD6rP+8dYPgzYGvV8WzAvJjObaWblZlZeXV3dgbBERJLPD+dvpGdOJndfOjrsUGKa\nVNCboX1zNepXyNqbtH8MjAPOBXYC/9HRQNx9lrsXuXtRXl7XDT8nIhK2jdVH+O37O7jj4tH065ET\ndjgxmRklp+WzeMMeTtQ3hB1O2mpX0nb33e7e4O6NwGNEqsKb2g5EN38cHswTEZEoP5q/kW5ZGcyY\nOibsUFpUUpjPsdoG3qpozxVTiYd2JW0zGxL19BZgZYxiS4EJZjbGzHKATwEvt2d/IiKpauu+Y/x6\n+XY+PWUUg3p1CzucFl0ybhC52RmqIg9RW275eh5YAkwys21mdg/wb2a2wszeB6YBfx2UHWpmrwK4\nez3wAPAasBp4wd1XddLrEBFJSj9esJFMM2ZenvijaOVmZ3LJuEGUrqnCXb2jhaHVGwHd/fYYs2c3\nU3YHcH3U81eBj9wOJiIisPPgcX5Rvo1PFg1ncN/csMNpk2mF+ZSuqWJj9VHG5/cKO5y0ox7RRERC\nMmthBQ3u3HfFuLBDaTPd+hUuJW0RkRBUHz7B829v4ZbJwxgxoEfY4bTZsH7dKRzcm3lr1KVpGJS0\nRURCMHvxJk7UN/KF4uQ5yz5pWmE+5ZX7OXi8LuxQ0o6StohIFztwrJanl1Ry49lDGZuXfNeFpxfm\nU9/oLFqvjrC6mpK2iEgXm/NGJUdrG3hg2viwQ2mXySP7069Htm79CoGStohIFzpUU8eTb2zimjMK\nmDS4d9jhtEtmhlE8MY8Fa6tpaNStX11JSVtEpAs9vWQzh2rqeWDahLBD6ZBphfnsPVrLe9sOhB1K\nWlHSFkkjwQA/VWa2MmreADOba2brg7+xBgDCzO4Myqw3szu7LurUcay2ntmLN1E8KY+zhvcNO5wO\nuWJiHhmmW7+6mpK2SHp5Eri2ybwHgXnuPgGYFzz/EDMbAHwLuJDIWAPfai65S/Oee2sL+47W8sWS\n5LyWHa1fjxyKRg3Qde0upqQtkkbcfSHQdLSHm4GngumngI/HWPUaYK6773P3/cBcPpr8pQU1dQ3M\nWljBxWMHcv6oAWGHExfTCvNZteMQuw7WhB1K2mi1G1MRSXkF7r4zmN4FFMQoMwzYGvV8WzDvI8xs\nJjAToKCggLKyshZ3fuTIkVbLJKJTjbt0Sx1Vh2u5q9BCf73xes97H24E4NGXF1E8IrvD22tNunxW\nWqKkLSJ/5O5uZh1qDuzus4BZAEVFRV5cXNxi+bKyMlork4hOJe66hkb+7vtlnDeyH5//xCWYWecG\n14p4vefuzo9XzWdbYx+Ki4s6Hlgr0uGz0hpVj4vI7pPD7QZ/Y12k3A6MiHo+PJgnbfDiO9vZfuA4\nX5w+IfSEHU9mRklhPm9s2ENNXUPY4aQFJW0ReRk42Rr8TuClGGVeA642s/5BA7Srg3nSivqGRn5U\ntoEzh/WheGJe2OHEXUlhPsfrGnhrU9OmEtIZlLRF0oiZPQ8sASaZ2TYzuwd4CLjKzNYDVwbPMbMi\nM3scwN33Ad8FlgaP7wTzpBWvrNhJ5d5jPDAttc6yT7p43EByszMoXa0BRLqCrmmLpBF3v72ZRdNj\nlC0HZkQ9nwPM6aTQUlJjo/NI6QYmFvTi6tNjte9LfrnZmVw6bhCla6v4tntK/jBJJDrTFhHpJK9/\nsIv1VUe4f9p4MjJSN5mVnJbP1n3H2Vh9JOxQUl6rSbuZHpS+b2ZrzOx9M3vRzPo1s26lma0ws+Vm\nVh7PwEVEEpm784PSDYwZ1JMbzx4adjidatqkfADmrVZHK52tLWfaT/LRThTmAme6+9nAOuBvW1h/\nmruf6+6dfz+AiEiCKFtbzaodh/h88TgyU/gsG2Bov+4UDu6t3tG6QKtJO1YPSu7+urvXB0/fJHL7\nh4iIEDnLfrh0PcP6deeWyTH7oEk500/Lp3zzfg4erws7lJQWj2vanwN+18wyB143s2VBL0nNMrOZ\nZlZuZuXV1RpYXUSS1x827uXdLQf4fPE4sjPTo+lQSWE+DY3OwnX6/u5MHfo0mdnfAfXAs80Uuczd\nzwOuA+43s8ub25a7z3L3IncvystLvXsZRSR9/KB0PQV9unHr+elTCXnuiP7075GtUb86WbuTtpnd\nBdwIfMbdY3Z76O7bg79VwItERgcSEUlZSyv38WbFPmZePo7c7Myww+kymRlG8aR85q+toqGxQz3h\nSgvalbTN7Frg68BN7n6smTI9zaz3yWkiPSitjFVWRCRVPFK6gYE9c7h9yojWC6eYaYX57D9Wx/Kt\nB8IOJWW15ZavWD0oPQL0BuYGt3M9GpQdamavBqsWAIvN7D3gbeAVd/99p7wKEZEE8P62AyxYV809\nU8fQIyf9+q66YkIemRmmKvJO1OqnqpkelGY3U3YHcH0wXQGc06HoRESSyCOlG+iTm8UdF40KO5RQ\n9O2Rzfmj+jNvTRVfvWZS2OGkpPRo1igi0snW7DrE6x/s5u5Lx9A7t/PHlk5UJYX5rN55iJ0Hj4cd\nSkpS0hYRiYMfzt9Iz5xM7r50dNihhGp6YaR3tPlrdOtXZ1DSFhHpoI3VR/jt+zu44+LR9OuRE3Y4\noRqf34vh/btTukajfnUGJW0RkQ760fyNdMvKYMbUMWGHEjozo6Qwnzc27KWmriHscFKOkraISAds\n3XeMXy/fzqenjGJQr25hh5MQSgrzOV7XwJsVe8MOJeUoaYuIdMCPF2wk04yZl48NO5SEcdHYgXTP\nztQAIp1ASVtEpJ12HjzOL8q38cmi4Qzumxt2OAkjNzuTS8cPpHRNFc10mCntpKQtItJOsxZW0ODO\nfVeMCzuUhFNSWMC2/cdZX3Uk7FBSipK2iEg7HDzhPP/2Fm6ZPIwRA3qEHU7CmVYYGfhJVeTxpaQt\nItIOr1XWcaK+kS8U6yw7liF9u3P6kD5K2nGWfp3jhmz0g6+0WqbyoRu6IBIRaa/9R2sp3VLHjWcP\nZWxer7DDSVglhfn8eMFGDh6ro2+P9O0lLp50pi0icoqefnMzNQ1w/zSdZbdkWmE+DY3OgvXqHS1e\nlLRFRE5BTV0DP1lSydmDMikc3CfscBLauSP6MaBnjkb9iiMlbRGRU/DS8u3sOVLLtWNU3duazAyj\neGIeZWuraGjUrV/xoKQtItJG7s7jizZx2pA+nDZAX59tMa0wn/3H6li+dX/YoaQEfepERNqobF01\n66uOcO/UMZhZ2OEkhcsn5pGZYcxbrSryeFDSFhFpo8cXVVDQpxs3nj007FCSRt/u2RSN6q9bv+Kk\nTUnbzOaYWZWZrYyaN8DM5prZ+uBv/2bWvTMos97M7oxX4CIiXWnVjoO8sWEvd10yhpwsne+ciumn\n5bNm12F2HDgedihJr62fvCeBa5vMexCY5+4TgHnB8w8xswHAt4ALgSnAt5pL7iIiiezxRZvomZPJ\npy8cGXYoSaekMB9Iz97Rdh+qiWv/621K2u6+ENjXZPbNwFPB9FPAx2Oseg0w1933uft+YC4fTf4i\nIglt58Hj/Oa9Hdx2wQj6dler8VM1Lq8XIwZ0T7tbv7buO8YNDy/i1xvq4rbNjtTxFLj7zmB6F1AQ\no8wwYGvU823BvI8ws5lmVm5m5dXVuhFfRBLHk3+opNGdz106JuxQkpKZMb2wgDc27qGmriHscLrE\nwWN13PXE29TWN3LhkPh1PhqXCzMeOffv0Pm/u89y9yJ3L8rLy4tHWCIiHXbkRD3PvbWF684cooFB\nOmBaYT41dY0s2bg37FA63Yn6Bv7ymXK27DvGrL8oYmiv+LWB6MiWdpvZEIDgb6x6j+3AiKjnw4N5\nIiJJ4YWlWzlcU8+MqTrL7ogLxwyge3Zmyl/Xdnce/OUK3qzYx/dvPYeLxg6M6/Y7krRfBk62Br8T\neClGmdeAq82sf9AA7epgnohIwqtvaGTOG5soGtWfySPVhrYjcrMzuWzCIErXVMW1YVai+a//W8+L\n727nq1dP5OOTY14N7pC23vL1PLAEmGRm28zsHuAh4CozWw9cGTzHzIrM7HEAd98HfBdYGjy+E8wT\nEUl4r63azbb9x5kxdWzYoaSEksJ8th84zrrdR8IOpVP8vHwrD89bz21Fw7l/2vhO2Uebro67++3N\nLJoeo2xQfkiZAAAX/klEQVQ5MCPq+RxgTruiExEJibvz2KIKRg3swVWnx2pnK6dq2qQ/3fo1aXDv\nkKOJr8Xr9/C3v1rBZeMH8c+3nNVpPeaphwARkRiWbd7P8q0HuOeyMWRmqMvSeBjcN5czhvahdM3u\nsEOJq7W7DvP5Z5YxLq8XP/rseWRndl5qVdIWEYlh1sIK+vXI5tbzh4cdSkopKcxn2eb9HDhWG3Yo\ncbH7UA13P/E23XMymXP3BfTJ7dz7+JW0RQQAM/uSma00s1Vm9uUYy4vN7KCZLQ8e3wwjzq6wac9R\n5q7ezWcvHEWPnPjdYyuRpN3osGBd8vfHcfREPfc8tZQDx+uYc9cFDOvXvdP3qaQtIpjZmcC9RLob\nPge40cxitaRZ5O7nBo/vdGmQXWjO4k1kZ2TwF5eMCjuUlHPO8H4M7JmT9Ld+1Tc08sXn3+WDHYd4\n5NOTOXNY3y7Zr5K2iACcBrzl7sfcvR5YAHwi5JhCsf9oLT9ftpWbzx1Kfu/csMNJORkZxhWT8liw\nrpqGxuS89cvd+cfffEDpmir+8eYzKSnsuoaKqvcREYCVwD+b2UDgOHA9UB6j3MVm9h6wA/iqu69q\nWsDMZgIzAQoKCigrK2txx0eOHGm1TFd6eWMtNXWNnJO7t8W4Ei3uUxF27IMb6zlwrI45L5UyoX9m\nm9cLO+6Tfr+pjp+ureW6MdmMqNlEWdmmFsvHM24lbRHB3Veb2feA14GjwHKgaSfR7wCj3P2ImV0P\n/BqYEGNbs4BZAEVFRV5cXNzivsvKymitTFc5Ud/A196Yz+UT8/jsx6a0WDaR4j5VYcd+Xk0ds96f\ny77uwyguLmzzemHHDfC7FTv52WvvcP1Zg3nk9vPIaMOdBfGMW9XjIgKAu8929/Pd/XJgP7CuyfJD\n7n4kmH4VyDazQSGE2mleWr6D6sMnuFddlnaqPrnZFI3un3Sjfi3bvJ8v/2w5k0f04z9vO7dNCTve\nlLRFBAAzyw/+jiRyPfu5JssHW9BjhJlNIfL9kTKjP7g7sxdtonBwby4bn1K/RRLS9MIC1uw6zPYD\nx8MOpU027z3KvT8pZ3DfXB77iyJys9terR9PStoictIvzewD4DfA/e5+wMzuM7P7guW3AiuDa9oP\nA5/yFOpEeuH6PazdfZgZU8d2Wm9W8ifTCv/UO1qi23+0lrufWEqjO0/cdQEDe3ULLRZd0xYRANx9\naox5j0ZNPwI80qVBdaHHFlZQ0KcbN50zNOxQ0sK4vJ6MGtiD+WuquOOixL21rqaugZlPl7Nt/3Ge\nvfdCxub1CjUenWmLSNr7YMchFm/Yw52XjCYnS1+LXcHMmDYpnzc27OF4bdM2j4mhsdH52i/eZ2nl\nfv79tnO4YPSAsENS0hYReXxxBT1yMvnMlMQ940tFJYX5nKhvZEnFnrBDiek/5q7lN+/t4OvXTkqY\nGhglbRFJa7sP1fCb93ZwW9EI+vbo3H6j5cMuHDuAHjmZCXld+6dvb+GH8zdy+5QRfP6KcWGH80dK\n2iKS1p78QyUNjc7nLtVtXl2tW1Yml40fROnqKhKpTePCddX83a9XcsXEPL5785kJ1TBRDdES0OgH\nX2m1TOVDN3RBJCKp7eiJep59czPXnDGYkQN7hB1OWiopzOf1D3azdvdhCgf3CTscVu88xBeefYeJ\nBb354WfOI6sTh9lsj8SKRkSkC/28fCuHauqZMXVs2KGkrUS69WvXwRrufmIpvbplMeeuInp1S7zz\n2nYnbTObFDVE33IzO9R0OL90GspPRJJLQ6Mz541KzhvZj/NH9Q87nLRV0CeXM4f1oXR1uEn7yIl6\n7n5yKYdrIsNsDunb+cNstke7f0a4+1rgXAAzywS2Ay/GKLrI3W9s735ERDrD66t2sWXfMf72urb3\nfS2do6SwgEdK17P/aC39e+Z0+f7rGxq5/9l3WLf7MLPvLOL0oeFX0zcnXtXj04GN7r45TtsTEelU\njy2qYOSAHlx9xuCwQ0l7JYX5NDosWFfd5ft2d/7hpVUsWFfNd28+k+JJ+V0ew6mIV9L+FPB8M8su\nNrP3zOx3ZnZGcxsws5lmVm5m5dXVXf+PE5H0sWzzPt7ZcoB7LhtDZgiDPsiHnT2sL4N65YRyXft/\nF1bw/Ntb+HzxOD594cgu3/+p6nDSNrMc4Cbg5zEWnxzK7xzgB0SG8ovJ3We5e5G7F+Xl5XU0LBGR\nZj22cBN9u2fzyaLhYYciQEaGUTwpnwXrqqlvaOyy/f72/R089Ls1fOycoXzt6kldtt+OiMeZ9nXA\nO+6+u+mCdBjKT0SSy+a9R3ntg1185sKR9MhJvNbB6aqkMJ+Dx+t4Z8uBLtlfeeU+/uaF97hgdH++\nf+vZoQyz2R7xSNq300zVeKoP5SciyWfO4k1kZRh3XjI67FAkymUTBpGVYV1SRb5pT2SYzWH9ujPr\njvCG2WyPDiVtM+sJXAX8Kmpe2gzlJyLJ5cCxWl4o38ZN5wyjoE9u2OFIlD652UwZM4D5nZy09x2t\n5e4n3sbMeOKuC0Jprd4RHaobcvejwMAm89JmKL9k0Jbe1RKReoWTzvDsW1s4XtfAjKnqsjQRlRTm\n80+vrGbb/mMM7x//Hupq6hq49yfl7DhYw/P3XsToQT3jvo/Oph7RRCQt1NY38tQfKpk6YRCnDUnc\n+3DT2cne0TrjbLux0fnKC++xbPN+/vvPz03aDnWUtEUkLbz83g6qDp9Ql6UJbOygnowe2IN5nZC0\nv/faGl5ZsZNvXF/I9WcNifv2u4qStoikPHfn8UUVTCrozeUTdANLojIzphXms2TjXo7XNsRtu8+8\nuZn/XVDBZy8ayb1J/qNNSVtEUt6i9XtYs+swM6aOSahhFuWjphcWcKK+kT9s3BOX7c1fU8U3X1rJ\ntEl5fPtjZyT9/19JW0RS3mOLKsjr3Y2bzh0adijSiiljBtAzJzMuVeQrtx/k/ufe4bQhfXjk04k3\nzGZ7JP8rEBFpwZpdh1i0fg93XTKablnJcz9uusrJyuCyCYOYv6aKjtwhvOPAce55ain9umcz564L\n6JmAw2y2h5K2iKS0xxdtont2Jp9Jgn6lJWJ6YQE7D9awZtfhdq1/uKaOzz25lGMnGphz9wUpdU++\nkraIpKyqQzW8tHw7nywaTr8eydWJRjorLoyMP9Ge3tHqGhr5wrPvsKHqCD/+7PkUDk6t2/uUtEUk\nZT21pJL6Rudzl6ozlWSS3zuXs4b1PeWk7e78/YsrWbR+D/9yy1lcloJ3Cihpi0hKOlZbzzNvbuHq\n0wuSsuerdFdSmM+7W/az72htm9f5UdlGfla+lS+WjOe2C0Z0YnThSY0r8x2g7jK7VrJ2qyrJ5xfL\ntnHweF3S35ebrkoK8/mfeetZsK6KWya3PoTqS8u38/3X1nLzuUP5m6smdkGE4dCZtoiknIZGZ/bi\nTUwe2S9pu6tMd2cN68ugXt0oXVPdatm3KvbytZ+/z5QxA/i3W89O+nuxW6KkLSIpZ+4Hu9m89xj3\nTh2b0l/gqSwjw5g2KY8Fa6uob2hsttzG6iPMfHoZwwd0Z9Yd56f8bX1K2iKSch5bVMGIAd255ozB\nYYciHVBSmM+hmnqWbd4fc/meIye4+4mlZGcaT909JS3uEFDSFpGU8s6W/SzbvJ/PXTqGzAydZSez\nyyYMIjvTKF370VbkNXUNzHiqnKrDNTx+5wWMGBD/oTwTkZK2iKSUxxdV0Cc3i9uKUrP1cDrpnZvN\nlDEDKF394aTd2Oh8+afLeW/bAf77zydz7oh+IUXY9ZS0RSRlbN13jN+v3MWnLxyVMt1Wprtpk/JZ\nX3WErfuO/XHev7y6mt+v2sXf33A6156ZXpdAOpy0zazSzFaY2XIzK4+x3MzsYTPbYGbvm9l5Hd2n\niEgssxdvIsOMuy4ZHXYoEifTTysAYH5QRf7UHyp5fPEm7rpkNJ+7dHSIkYUjXj9Fp7l7c+OoXQdM\nCB4XAj8O/oqIxM3BY3W8UL6Vm84ZyuC+qdPXdLobM6gnYwb1ZN7qKs7tVc8P3l3Flafl8w83np6W\ndwZ0Rf3RzcBPPDJcy5tm1s/Mhrj7zi7Yt4ikiefe3sKx2gZmqDOVlDNtUj7PvLmZJTRyxtC+PHz7\n5LRtZBiPa9oOvG5my8xsZozlw4CtUc+3BfM+xMxmmlm5mZVXV7d+M72IyEm19Y08+YdNXDZ+EKcP\nTa0BIgSmn5ZPbUMjvbON2XcV0SMnfdsrxOOVX+bu280sH5hrZmvcfeGpbsTdZwGzAIqKito/iKqI\npJ3fvr+D3YdO8L0/OzvsUKQTXDhmAF+7ZhIDj20hv3d6X/ro8Jm2u28P/lYBLwJTmhTZDkTfezE8\nmCciCcTMvmRmK81slZl9OcbyhGxU6u7MWljBxIJeXDExL+xwpBNkZWZw/7TxDO6pG5469A6YWU8z\n631yGrgaWNmk2MvAXwQH/EXAQV3PFkksZnYmcC+RH93nADea2fgmxaIblc4k0qg0dG9s2MuaXYeZ\ncZm6LJXU19GfLQXAYjN7D3gbeMXdf29m95nZfUGZV4EKYAPwGPCFDu5TROLvNOAtdz/m7vXAAuAT\nTcr8sVGpu78J9DOzIV0daFOPLapgUK9u3Dx5aNihiHS6Dl3TdvcKIr/Km85/NGragfs7sh8R6XQr\ngX82s4HAceB6oGm/C801Kg2t5mzd7sMsWFfNV66amPIDRYiAxtMWEcDdV5vZ94DXgaPAcqChPdsK\n7iKZCVBQUEBZWVmL5Y8cOdJqmebMXnGCnAwY07CNsrKubSrTkbjDlqyxK24lbREJuPtsYDaAmf0L\nkTPpaG1qVNr0TpDi4uIW91tWVkZrZWKpOlzDW3Pnc9uUkdx49VmnvH5HtTfuRJCssStu9T0uIoHg\ntk3MbCSR69nPNSmSUI1Kn16ymbrGRu65TJ2pSPrQmbaInPTL4Jp2HXC/ux842aA0aKfyKpFr3RuA\nY8DdYQV6vLaBZ97czFWnFTBmUM+wwhDpcimdtEc/+EpK708kntx9aox5Cdmo9BfvbGP/sTruvVxn\n2ZJeVD0uIkmlodGZvaiCc0b0o2hU/7DDEelSStoiklT+b/VuKvce496pY9SZiqQdJW0RSSqPL6pg\nWL/uXHvG4LBDEelyStoikjSWbz3A0sr9fO6yMWRl6utL0o8+9SKSNB5bVEHv3Cz+/IIRrRcWSUFK\n2iKSFLbuO8bvVuzk01NG0qtbSt/4ItIsJW0RSQpPvFFJhhl3XTo67FBEQqOkLSIJ7+DxOn62dAsf\nO2coQ/p2DzsckdAoaYtIwvvp21s4WtvAjKljwg5FJFRK2iKS0GrrG3nijUouGTeQM4b2DTsckVCp\nNYckrbZ0G1v50A1dEIl0pldW7GDXoRr+9RNdP5KXSKLRmbaIJCx357GFmxif34srJuaFHY5I6Nqd\ntM1shJnNN7MPzGyVmX0pRpliMztoZsuDxzc7Fq6IpJMlG/fywc5DzLhsDBkZ6rJUpCPV4/XAV9z9\nHTPrDSwzs7nu/kGTcovc/cYO7EdE0tRjiyoY1CuHj08eFnYoIgmh3Wfa7r7T3d8Jpg8DqwEdWSIS\nFxuqDjN/bTV3XDSa3OzMsMMRSQhxuaZtZqOBycBbMRZfbGbvmdnvzOyMFrYx08zKzay8uro6HmGJ\nSBJ7fNEmumVl8NmLRoYdikjC6HDSNrNewC+BL7v7oSaL3wFGufs5wA+AXze3HXef5e5F7l6Ul6cG\nJyLprPrwCX717nZuPX84A3t1CzsckYTRoaRtZtlEEvaz7v6rpsvd/ZC7HwmmXwWyzWxQR/YpIqnv\n6Tc3U9fQyD2XqTMVkWgdaT1uwGxgtbv/ZzNlBgflMLMpwf72tnefIpL6jtc28Mybm5leWMDYvF5h\nhyOSUDrSevxS4A5ghZktD+Z9AxgJ4O6PArcCnzezeuA48Cl39w7sU0RS3C/f2ca+o7Xcqy5LRT6i\n3Unb3RcDLd446e6PAI+0dx8taUtvWCJtEc/Pknpg65jGRmfO4k2cPbwvU8YMCDsckYSjHtFEJGHM\nW1NFxZ6jzJg6luDKmohEUdIWkYTx2KIKhvXrzvVnDg47FJGEpKQtIgnh/W0HeHvTPu6+dDRZmfpq\nEolFR4aIJITHFm2id7cs/vyCEWGHIpKwlLRFJHTbDxzn1RU7uf3CkfTOzQ47HJGEpaQtIqF7YvEm\nDLjrktFhhyKS0JS0RSRUx+qcny7dyg1nD2Fov+5hhyOS0JS0RSRUC7bVc+REPfdOHRt2KCIJT0lb\nREJT19DI3M11XDR2AGcO6xt2OCIJryPdmIpIE/HqXS1delZ7dcVO9tW4zrJF2khn2iISmp45WZyX\nn8m0SflhhyKSFHSmLSKhufL0ArKqcsnIUJelIm2hM20REZEkoaQtIiKSJJS0RUREkoSStoiISJJQ\n0hYREUkSHUraZnatma01sw1m9mCM5d3M7GfB8rfMbHRH9icincfM/trMVpnZSjN73sxymyy/y8yq\nzWx58JgRVqwi6ardSdvMMoEfAtcBpwO3m9npTYrdA+x39/HAfwHfa+/+RKTzmNkw4K+AInc/E8gE\nPhWj6M/c/dzg8XiXBikiHTrTngJscPcKd68Ffgrc3KTMzcBTwfQvgOlmphsyRRJTFtDdzLKAHsCO\nkOMRkSY60rnKMGBr1PNtwIXNlXH3ejM7CAwE9jTdmJnNBGYGT4+Y2doOxBYPgwjitASsH+jEmP74\nuk9VEr9P7X7NnaWNcY+K1/7cfbuZ/TuwBTgOvO7ur8co+mdmdjmwDvhrd9/atEA7juWEe//bKFnj\nhuSNPZXjbtPxnDA9orn7LGBW2HGcZGbl7l4UdhxdLR1fdzq+5qbMrD+RmrExwAHg52b2WXd/JqrY\nb4Dn3f2Emf0lkVq0kqbbOtVjOVnf/2SNG5I3dsXdserx7cCIqOfDg3kxywRVbn2BvR3Yp4h0jiuB\nTe5e7e51wK+AS6ILuPtedz8RPH0cOL+LYxRJex1J2kuBCWY2xsxyiDRaeblJmZeBO4PpW4FSd/cO\n7FNEOscW4CIz6xG0O5kOrI4uYGZDop7e1HS5iHS+dlePB9eoHwBeI9LSdI67rzKz7wDl7v4yMBt4\n2sw2APuI3Ro1USVMVX0XS8fXnY6v+UPc/S0z+wXwDlAPvAvManI8/5WZ3RQs3wfcFafdJ+v7n6xx\nQ/LGnvZxm058RUREkoN6RBMREUkSStoiIiJJQkk7BjOrNLMVQVeN5WHH01nMbI6ZVZnZyqh5A8xs\nrpmtD/72DzPGeGvmNX/bzLZHdc95fZgxppPWukJORLE+Q8nAzEaY2Xwz+yDorvZLYcfUFmaWa2Zv\nm9l7Qdz/GHZMp8LMMs3sXTP7bTy2p6TdvGlBV41Jd0/gKXgSuLbJvAeBee4+AZgXPE8lT/LR1wzw\nX1Hdc77axTGlpTZ2hZyIniT2ZyjR1QNfcffTgYuA+5Pk/T4BlLj7OcC5wLVmdlHIMZ2KLxHHOy2U\ntNOYuy8k0go4WnTXs08BH+/SoDpZM69ZwtGWrpATTrJ+htx9p7u/E0wfJpJIhoUbVes84kjwNDt4\nJEULajMbDtxApF+DuFDSjs2B181sWdAlYzopcPedwfQuoCDMYLrQA2b2flD1mVKXBBJYrK6QEz6J\npIJgxMXJwFvhRtI2QRXzcqAKmOvuSRE38N/A14HGeG1QSTu2y9z9PCLVdvcHfS2nnaAjnKT4RdtB\nPwbGEal62wn8R7jhiHQeM+sF/BL4srsfCjuetnD3Bnc/l0jPm1PM7MywY2qNmd0IVLn7snhuV0k7\nBnffHvytAl4kUo2XLnaf7Pkq+FsVcjydzt13B18KjcBjpNf/O0xt6QpZ4sjMsokk7Gfd/Vdhx3Oq\n3P0AMJ/kaFNwKXCTmVUSufRTYmbPtLxK65S0mzCznmbW++Q0cDWQVK1EOyi669k7gZdCjKVLNOme\n8xbS6/8dprZ0hSxxEnRPOxtY7e7/GXY8bWVmeWbWL5juDlwFrAk3qta5+9+6+3B3H03ks13q7p/t\n6HYTZpSvBFIAvBgM+50FPOfuvw83pM5hZs8DxcAgM9sGfAt4CHjBzO4BNgO3hRdh/DXzmovN7Fwi\nlwIqgb8MLcA00lxXyCGH1apYnyF3nx1uVG1yKXAHsCK4PgzwjSS4W2II8FRwt0EG8IK7x+X2qWSk\nbkxFRESShKrHRUREkoSStoiISJJQ0hYREUkSStoiIiJJQklbREQkSShpi4iIJAklbRERkSTx/wGZ\nKPUtmPr67gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86737ead68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 500/25000 [06:44<22:08:50,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llh=2.430, mean score=9.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 510/25000 [06:50<4:23:01,  1.55it/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-07a1c9bb031b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     loss_history.append(\n\u001b[0;32m----> 9\u001b[0;31m             llh_trainer.train_step(*sample_batch(train_words,word_to_translation,32)))\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mREPORT_FREQ\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm,trange #or use tqdm_notebook,tnrange\n",
    "\n",
    "loss_history=[]\n",
    "editdist_history = []\n",
    "\n",
    "for i in trange(25000):\n",
    "    loss_history.append(\n",
    "            llh_trainer.train_step(*sample_batch(train_words, word_to_translation, 32)))\n",
    "    \n",
    "    if (i+1)%REPORT_FREQ==0:\n",
    "        clear_output(True)\n",
    "        current_scores = score()\n",
    "        editdist_history.append(current_scores.mean())\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.subplot(121)\n",
    "        plt.title('val score distribution')\n",
    "        plt.hist(current_scores, bins=20)\n",
    "        plt.subplot(122)\n",
    "        plt.title('val score / traning time')\n",
    "        plt.plot(editdist_history)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"llh=%.3f, mean score=%.3f\"%(np.mean(loss_history[-10:]),np.mean(editdist_history[-10:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ארטור ראסיזאדה; -> carde darder;\n",
      "הנרי וילסון; -> marde darde;\n",
      "just dance 4; -> carin sarde;\n",
      "אמריקאי בפריז; -> marde darder;\n",
      "ילנה דמנטייבה; -> marde darder;\n",
      "טרנסקאי; -> bolis;\n",
      "חתלתלת; -> marder sher;\n",
      "משתמש:yambaram; -> marde darder;\n",
      "autorun.inf; -> bolis mard;\n",
      "ביולוג; -> boller;\n"
     ]
    }
   ],
   "source": [
    "for word in train_words[:10]:\n",
    "    print(\"%s -> %s\"%(word, model.translate(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Policy gradient (3 pts)\n",
    "\n",
    "First we need to define loss function as a custom theano operation.\n",
    "\n",
    "The simple way to do so is\n",
    "```\n",
    "@theano.compile.as_op(input_types,output_type(s),infer_shape)\n",
    "def my_super_function(inputs):\n",
    "    return outputs\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Your task__ is to implement `_compute_levenshtein` function that takes matrices of words and translations, along with input masks, then converts those to actual words and phonemes and computes min-levenshtein via __get_distance__ function above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@theano.compile.as_op([T.imatrix]*4, [T.fvector], lambda _, shapes: [shapes[0][:1]])\n",
    "def _compute_levenshtein(words_ix, words_mask, trans_ix, trans_mask):\n",
    "    \"\"\"\n",
    "    A custom theano operation that computes levenshtein loss for predicted trans.\n",
    "    \n",
    "    Params:\n",
    "    - words_ix - a matrix of letter indices, shape=[batch_size, word_length]\n",
    "    - words_mask - a matrix of zeros/ones, \n",
    "       1 means \"word is still not finished\"\n",
    "       0 means \"word has already finished and this is padding\"\n",
    "    \n",
    "    - trans_ix - a matrix of output letter indices, shape=[batch_size, translation_length]\n",
    "    - trans_mask - a matrix of zeros/ones, similar to words_mask but for trans_ix\n",
    "    \n",
    "    \n",
    "    Please implement the function and make sure it passes tests from the next cell.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #convert words to strings\n",
    "    # <your code here>\n",
    "    length = np.sum(words_mask, axis=1)\n",
    "    words = [[source_letters[ix] for ix in row] for row in words_ix]\n",
    "    words = [\"\".join(row[:length[i]]) for i, row in enumerate(words)]\n",
    "\n",
    "    assert type(words) is list\n",
    "    assert type(words[0]) is str \n",
    "    assert len(words)==len(words_ix)\n",
    "    \n",
    "    #convert translations to lists\n",
    "    # <your code here>\n",
    "    length = np.sum(trans_mask, axis=1)\n",
    "    translations = [[target_letters[ix] for ix in row] for row in trans_ix]\n",
    "    translations = [\"\".join(row[:length[i]]) for i, row in enumerate(translations)]\n",
    "\n",
    "    assert type(translations) is list\n",
    "    assert type(translations[0]) is str\n",
    "    assert len(translations)==len(trans_ix)\n",
    "\n",
    "    #computes levenstein distances. can be arbitrary python code.\n",
    "    distances = [get_distance(word, trans) for word, trans in zip(words, translations)]\n",
    "    \n",
    "    assert type(distances) in (list, tuple, np.ndarray) and len(distances) == len(words_ix)\n",
    "    \n",
    "    distances = np.array(list(distances), dtype='float32')\n",
    "    return distances\n",
    "\n",
    "#forbid gradient\n",
    "from theano.gradient import disconnected_grad\n",
    "def compute_levenshtein(*args):\n",
    "    return disconnected_grad(_compute_levenshtein(*[arg.astype('int32') for arg in args]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test suite to make sure your implementation is correct. Hint: if you run into any bugs, feel free to use print from inside _compute_levenshtein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test suite\n",
    "#sample random batch of (words, correct trans, wrong trans)\n",
    "batch_words = np.random.choice(train_words, size=100 )\n",
    "batch_trans = list(map(random.choice, map(word_to_translation.get, batch_words )))\n",
    "batch_trans_wrong = np.random.choice(all_translations, size=100)\n",
    "\n",
    "batch_words_ix = T.constant(as_matrix(batch_words, source_to_ix))\n",
    "batch_trans_ix = T.constant(as_matrix(batch_trans, target_to_ix))\n",
    "batch_trans_wrong_ix = T.constant(as_matrix(batch_trans_wrong, target_to_ix))\n",
    "\n",
    "batch_words_mask = get_mask_by_eos(T.eq(batch_words_ix, EOS_ix_source))\n",
    "batch_trans_mask = get_mask_by_eos(T.eq(batch_trans_ix, EOS_ix_target))\n",
    "batch_trans_wrong_mask = get_mask_by_eos(T.eq(batch_trans_wrong_ix, EOS_ix_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems alright!\n"
     ]
    }
   ],
   "source": [
    "#assert compute_levenshtein is zero for ideal translations\n",
    "correct_answers_score = compute_levenshtein(batch_words_ix,\n",
    "                                            batch_words_mask,\n",
    "                                            batch_trans_ix,\n",
    "                                            batch_trans_mask).eval()\n",
    "\n",
    "assert np.all(correct_answers_score==0), \"a perfect translation got nonzero levenshtein score!\"\n",
    "\n",
    "print(\"Everything seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems alright!\n"
     ]
    }
   ],
   "source": [
    "#assert compute_levenshtein matches actual scoring function\n",
    "wrong_answers_score = compute_levenshtein(batch_words_ix,batch_words_mask,\n",
    "                                            batch_trans_wrong_ix,batch_trans_wrong_mask).eval()\n",
    "\n",
    "true_wrong_answers_score = np.array(list(map(get_distance, batch_words,batch_trans_wrong)))\n",
    "\n",
    "assert np.all(wrong_answers_score==true_wrong_answers_score),\"for some word symbolic levenshtein is different from actual levenshtein distance\"\n",
    "\n",
    "print(\"Everything seems alright!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you got it working...\n",
    "\n",
    "\n",
    "* You may now want to __remove/comment asserts__ from function code for a slight speed-up.\n",
    "\n",
    "* There's a more detailed tutorial on custom theano ops here: [docs](http://deeplearning.net/software/theano/extending/extending_theano.html), [example](https://gist.github.com/justheuristic/9f4ffef6162a8089c3260fc3bbacbf46)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-critical policy gradient\n",
    "\n",
    "In this section you'll implement algorithm called self-critical sequence training (here's an [article](https://arxiv.org/abs/1612.00563)).\n",
    "\n",
    "The algorithm is a vanilla policy gradient with a special baseline. \n",
    "\n",
    "$$ \\nabla J = E_{x \\sim p(s)} E_{y \\sim \\pi(y|x)} \\nabla log \\pi(y|x) \\cdot (R(x,y) - b(x)) $$\n",
    "\n",
    "Here reward R(x,y) is a __negative levenshtein distance__ (since we minimize it). The baseline __b(x)__ represents how well model fares on word __x__.\n",
    "\n",
    "In practice, this means that we compute baseline as a score of greedy translation, $b(x) = R(x,y_{greedy}(x)) $.\n",
    "\n",
    "Luckily, we already obtained the required outputs: `model.greedy_translations, model.greedy_mask` and we only need to compute levenshtein using `compute_levenshtein` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentnet.learning.generic import get_values_for_actions\n",
    "\n",
    "class trainer:    \n",
    "    \n",
    "    rewards = -compute_levenshtein(encoder.input_sequence,\n",
    "                                   encoder.input_mask,\n",
    "                                   model.predicted_translations,\n",
    "                                   model.mask)\n",
    "    \n",
    "    baseline = -compute_levenshtein(encoder.input_sequence,\n",
    "                                    encoder.input_mask,\n",
    "                                    model.greedy_translations,\n",
    "                                    model.greedy_mask)\n",
    "    \n",
    "    #compute advantage using rewards and baseline\n",
    "    advantage = rewards - baseline\n",
    "    \n",
    "    \n",
    "    #compute log_pi(a_t|s_t), shape = [batch, seq_length]\n",
    "    phoneme_logprobs = get_values_for_actions(model.logprobs_seq, model.predicted_translations)\n",
    "    \n",
    "    #policy gradient\n",
    "    J = phoneme_logprobs*advantage[:, None]\n",
    "    \n",
    "    loss = -T.sum(J*model.mask) / model.mask.sum()\n",
    "    \n",
    "    \n",
    "    #regularize with negative entropy\n",
    "    #note: you can find full policy distribution in model.probs_seq and similar\n",
    "    entropy = -get_values_for_actions(model.probs_seq, model.predicted_translations)* \\\n",
    "               get_values_for_actions(model.logprobs_seq, model.predicted_translations)\n",
    "\n",
    "    loss -= 0.01*(model.mask*entropy).sum() / model.mask.sum()\n",
    "    \n",
    "    \n",
    "    # Compute weight updates, clip by norm\n",
    "    grads = T.grad(loss,model.weights)\n",
    "    grads = lasagne.updates.total_norm_constraint(grads, 10)\n",
    "\n",
    "    updates = lasagne.updates.adam(grads, model.weights, learning_rate=1e-5) \n",
    "\n",
    "    train_step = theano.function([encoder.input_sequence], loss,\n",
    "                                 updates = model.auto_updates+model.greedy_auto_updates+updates)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy gradient training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/100000 [00:00<17:49:02,  1.56it/s]\u001b[A\n",
      "  0%|          | 2/100000 [00:01<17:34:00,  1.58it/s]\u001b[A\n",
      "  0%|          | 3/100000 [00:01<17:20:39,  1.60it/s]\u001b[A\n",
      "  0%|          | 4/100000 [00:02<17:18:51,  1.60it/s]\u001b[A\n",
      "  0%|          | 5/100000 [00:03<17:26:41,  1.59it/s]\u001b[A\n",
      "  0%|          | 6/100000 [00:03<17:22:34,  1.60it/s]\u001b[A\n",
      "  0%|          | 7/100000 [00:04<17:21:50,  1.60it/s]\u001b[A\n",
      "  0%|          | 28/100000 [00:17<17:35:25,  1.58it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-4bf02b7480f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     loss_history.append(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_translation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/root/.theano/compiledir_Linux-4.9-moby-x86_64-with-Ubuntu-16.04-xenial-x86_64-3.5.2-64/scan_perform/mod.cpp:4490)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in trange(100000):\n",
    "    loss_history.append(\n",
    "        trainer.train_step(sample_batch(train_words, word_to_translation, 32)[0])\n",
    "    )\n",
    "    \n",
    "    if (i+1)%REPORT_FREQ==0:\n",
    "        clear_output(True)\n",
    "        current_scores = score()\n",
    "        editdist_history.append(current_scores.mean())\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.subplot(121)\n",
    "        plt.title('val score distribution')\n",
    "        plt.hist(current_scores, bins=20)\n",
    "        plt.subplot(122)\n",
    "        plt.title('val score / traning time')\n",
    "        plt.plot(editdist_history)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"J=%.3f, mean score=%.3f\"%(np.mean(loss_history[-10:]),np.mean(editdist_history[-10:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.translate(\"EXAMPLE;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_translations = list(map(model.translate,tqdm(test_words)))\n",
    "distances = list(map(get_distance,test_words,predicted_translations))\n",
    "print (\"Mean Levenshtein distance:\",np.mean(distances))\n",
    "print (\"Median Levenshtein distance:\",np.median(distances))\n",
    "plt.hist(distances,range=[0,10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Make it actually work (5++ pts)\n",
    "\n",
    "In this section we want you to finally __restart with EASY_MODE=False__ and experiment to find a good model/curriculum for that task.\n",
    "\n",
    "We recommend the following architecture\n",
    "\n",
    "```\n",
    "encoder---decoder\n",
    "\n",
    "           P(y|h)\n",
    "             ^\n",
    " LSTM  ->   LSTM\n",
    "  ^          ^\n",
    " LSTM   ->  LSTM\n",
    "  ^          ^\n",
    "input       y_prev\n",
    "```\n",
    "\n",
    "with __both__ LSTMs having equal or more units than the default gru.\n",
    "\n",
    "\n",
    "It's okay to modify the code above without copy-pasting it.\n",
    "\n",
    "__Some tips:__\n",
    "* You will likely need to adjust pre-training time for such a network.\n",
    "* Supervised pre-training may benefit from clipping gradients somehow.\n",
    "* SCST may indulge a higher learning rate in some cases and changing entropy regularizer over time.\n",
    "* There's more than one way of sending information from encoder to decoder, especially if there's more than one layer:\n",
    "  * __Vanilla:__ layer_i of encoder last state goes to layer_i of decoder initial state\n",
    "  * __Intermediate layers:__ add dense (and possibly concat) layers between encoder last and decoder first.\n",
    "  * __Every tick:__ feed encoder last state _on every iteration_ of decoder.\n",
    "\n",
    "\n",
    "* It's often useful to save pre-trained model parameters to not re-train it every time you want new policy gradient parameters. \n",
    "* When leaving training for nighttime, try setting REPORT_FREQ to a larger value (e.g. 500) not to waste time on it.\n",
    "\n",
    "\n",
    "* (advanced deep learning) It may be a good idea to first train on small phrases and then adapt to larger ones (a.k.a. training curriculum).\n",
    "* (advanced nlp) You may want to switch from raw utf8 to something like unicode or even syllables to make task easier.\n",
    "* (advanced nlp) Since hebrew words are written __with vowels omitted__, you may want to use a small Hebrew vowel markup dataset at `he-pron-wiktionary.txt`.\n",
    "\n",
    "__Formal criteria__:\n",
    "\n",
    "To get 5 points we want you to build an architecture that:\n",
    "* _doesn't consist of single GRU_\n",
    "* _works better_ than single GRU baseline. \n",
    "* We also want you to provide either learning curve or trained model, preferably both\n",
    "* ... and write a brief report or experiment log describing what you did and how it fared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`[your report/log here or anywhere you please]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus assignments: [here](https://github.com/yandexdataschool/Practical_RL/blob/master/week8/8.2_bonus.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
