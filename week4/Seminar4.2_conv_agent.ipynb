{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[this demo requires doom installed either from gym-pool or from [ppaquette's repo](https://github.com/ppaquette/gym-doom)]\n",
    "\n",
    "## Basic Doom demo\n",
    "\n",
    "This demo solves DoomBasic env with a simple q-learning with experience replay.\n",
    "\n",
    "Video observation forces you to use ```CNN```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cpu, floatX=float32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=device=cpu, floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 14:23:44,649] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ppaquette_gym_doom\n",
    "from gym.wrappers import SkipWrapper\n",
    "from ppaquette_gym_doom.wrappers.action_space import ToDiscrete\n",
    "from agentnet.experiments.openai_gym.wrappers import PreprocessImage\n",
    "GAME_NAME = 'ppaquette/DoomBasic-v0'\n",
    "\n",
    "make_env = lambda: PreprocessImage(SkipWrapper(4)(ToDiscrete(\"minimal\")(gym.make(GAME_NAME))),\n",
    "                                   width=80, height=80, grayscale=True)\n",
    "\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation shape: (1, 80, 80)\n",
      "n_action: 4\n"
     ]
    }
   ],
   "source": [
    "#global params.\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "SEQ_LENGTH = 10\n",
    "FRAME_NUMBER = 4\n",
    "print(\"observation shape:\", observation_shape)\n",
    "print(\"n_action:\", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.0 False\n",
      "(1, 80, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f58a545fd68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n63QFeYMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58b185ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs, r, done, _ = env.step(1)\n",
    "print(r, done)\n",
    "print(np.shape(obs))\n",
    "plt.imshow(obs[0], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cpu, floatX=float32\n"
     ]
    }
   ],
   "source": [
    "#setup and import theano/lasagne. Prefer GPU\n",
    "%env THEANO_FLAGS=device=cpu, floatX=float32\n",
    "\n",
    "import theano, lasagne\n",
    "import theano.tensor as T\n",
    "from lasagne.layers import *\n",
    "\n",
    "from agentnet.memory import WindowAugmentation, LSTMCell\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "from agentnet.target_network import TargetNetwork\n",
    "from agentnet.experiments.openai_gym.pool import EnvPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of observation layer (None, 1, 80, 80)\n",
      "shape of prev wnd (None, 4, 1, 80, 80)\n",
      "reshape to (-1, 4, 80, 80)\n"
     ]
    }
   ],
   "source": [
    "#observation\n",
    "observation_layer = InputLayer((None,)+observation_shape,)\n",
    "print(\"shape of observation layer\", (None,)+observation_shape)\n",
    "\n",
    "#4-tick window over images\n",
    "prev_wnd = InputLayer((None, FRAME_NUMBER)+observation_shape)\n",
    "print(\"shape of prev wnd\", (None, FRAME_NUMBER)+observation_shape)\n",
    "new_wnd = WindowAugmentation(observation_layer, prev_wnd)\n",
    "        \n",
    "#reshape to (frame, h,w). If you don't use grayscale, 4 should become 12.\n",
    "wnd_reshape = reshape(new_wnd, (-1, FRAME_NUMBER*observation_shape[0])+observation_shape[1:])\n",
    "print(\"reshape to\", (-1, FRAME_NUMBER*observation_shape[0])+observation_shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define your NN which probably solve the environment. \n",
    "\n",
    "#### Tips:\n",
    "1. Main component are likely to be ```Conv2D``` and ```Pool2DLayer```\n",
    "2. Batch normalization here might speeds up training but may get unstable if you use small experience replay buffer\n",
    "3. Last layers should be Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lasagne.nonlinearities import elu, tanh, softmax\n",
    "net = {}\n",
    "net['conv1_1'] = Conv2DLayer(wnd_reshape, 32, 3, pad=1)\n",
    "net['conv1_2'] = Conv2DLayer(net['conv1_1'], 32, 3, pad=1)\n",
    "net['pool1'] = Pool2DLayer(net['conv1_2'], 2)\n",
    "net['conv2_1'] = Conv2DLayer(net['pool1'], 32, 3, pad=1)\n",
    "net['conv2_2'] = Conv2DLayer(net['conv2_1'], 32, 3, pad=1)\n",
    "net['pool2'] = Pool2DLayer(net['conv2_2'], 2)\n",
    "dense = DenseLayer(net['pool2'], num_units=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline for all qvalues\n",
    "qvalues_layer = DenseLayer(dense, num_units=n_actions, nonlinearity=None, name='qval')\n",
    "        \n",
    "#sample actions proportionally to policy_layer\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetnet = TargetNetwork(qvalues_layer)\n",
    "qvalues_old = targetnet.output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(qvalues_layer, qvalues_old),\n",
    "              agent_states={new_wnd: prev_wnd},\n",
    "              action_layers=action_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, W, b, W, b, W, b, qval.W, qval.b]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer, trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 14:23:46,191] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-08-24 14:23:46,200] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-08-24 14:23:46,212] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-08-24 14:23:46,225] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "pool = EnvPool(agent,\n",
    "               make_env, \n",
    "               n_games=4, #parallel games (only 1 so far)\n",
    "               max_size=1000) #experience replay pool holding last 1k sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 2 2 2 2 0]\n",
      " [2 0 2 2 1 2 3]\n",
      " [3 0 2 3 2 2 1]\n",
      " [2 0 2 2 2 2 0]]\n",
      "[[ -5.  -5.  -5.  -5.  -5.  -5.   0.]\n",
      " [ -5.  -5.  -5.  -5. -10.  -5.   0.]\n",
      " [ -5.  -5.  -5.  -5.  -5.  -5.   0.]\n",
      " [ -5.  -5.  -5.  -5.  -5.  -5.   0.]]\n",
      "CPU times: user 550 ms, sys: 950 ms, total: 1.5 s\n",
      "Wall time: 451 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_, action_log, reward_log, _, _, _ = pool.interact(7)\n",
    "\n",
    "print(action_log)\n",
    "print(reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(80, replace=True)\n",
    "\n",
    "_, _, _, _, (qvalues_seq, old_qvalues_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      qvalues_target=old_qvalues_seq,\n",
    "                                                      gamma_or_gammas=0.99)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "grad = T.grad(loss, weights)\n",
    "updates = lasagne.updates.adam(grad,\n",
    "                               weights,\n",
    "                               learning_rate=0.0005)\n",
    "\n",
    "train_step = theano.function([], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 14:23:56,478] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-08-24 14:23:56,491] Clearing 8 monitor files from previous run (because force=True was provided)\n",
      "[2017-08-24 14:23:56,716] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.0.39.video000000.mp4\n",
      "[2017-08-24 14:23:58,983] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.0.39.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 14:24:09,334] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.0.39.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 14:24:12,858] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-350.0\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0)\n",
    "untrained_reward = np.mean(pool.evaluate(save_path=\"./records\", record_video = True, n_games=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {0: untrained_reward}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have ```tqdm```, remove the first line and ```tqdm_notebook``` from second line\n",
    "\n",
    "Loop may take years to finish.\n",
    "\n",
    "You may consider interrupting early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "\n",
    "for i in range(2000):  \n",
    "   \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH, append=True)\n",
    "    \n",
    "    loss = train_step()\n",
    "    \n",
    "    targetnet.load_weights(0.01)\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 0.05 + 0.95*np.exp(-epoch_counter/200.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter%10==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%10==0:\n",
    "        rewards[epoch_counter] = pool.evaluate(record_video=False)\n",
    "    \n",
    "    epoch_counter += 1\n",
    "\n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time, rw = zip(*sorted(list(rewards.items()), key=lambda p: p[0]))\n",
    "plt.plot(time, list(map(np.mean, rw)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 14:25:32,071] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-08-24 14:25:32,081] Clearing 8 monitor files from previous run (because force=True was provided)\n",
      "[2017-08-24 14:25:32,293] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.1.39.video000000.mp4\n",
      "[2017-08-24 14:25:32,632] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.1.39.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 7 timesteps with reward=66.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 1 timesteps with reward=96.0\n",
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 14:25:33,466] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.1.39.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 6 timesteps with reward=71.0\n",
      "Episode finished after 1 timesteps with reward=96.0\n",
      "Episode finished after 7 timesteps with reward=66.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 6 timesteps with reward=71.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 6 timesteps with reward=71.0\n",
      "Episode finished after 2 timesteps with reward=91.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 14:25:34,654] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=81.0\n",
      "mean session score=79.250000.5\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=20, save_path=\"./records\", record_video=True)\n",
    "print(\"mean session score=%f.5\"%np.mean(rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<agentnet.resolver.epsilon_greedy.EpsilonGreedyResolver at 0x7f58a5419160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agentnet.utils.persistence import save, load\n",
    "#save for display\n",
    "load(action_layer, \"doombasic_dqn_2000.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "from random import choice\n",
    "#select the one you want\n",
    "videos = filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./records/\"))\n",
    "video_path = \"./records/\" + choice(videos)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework II\n",
    "Get it work. We want stable positive score :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus assignment II\n",
    "* Better env\n",
    "  * Switch to DoomDefendCenter, DoomHealthGathering, DoomDeathmatch __or__ any atari game you want.\n",
    "  * Try to get `better_than_random` score on any of those environments __(2+++ pts)__\n",
    "  * Deploy a better network. Doom will likely need some recurrent netsle\n",
    "     * Find an arcitecture which maxsimizes score __(bonus points depend on your ```mean_reward```)__  \n",
    "     * Bonus can get large as you approach state-of-the-art\n",
    "     \n",
    "* Deploy a different RL algorithm\n",
    "  * Try at least two RL algorithms which had been learned during the course and try to compare them on ```mean_reward``` with similar training time (**plot** or **table** would be good idea) __(3 pts)__\n",
    "  * See the note in assignment 4.1 on how to train on-policy\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
