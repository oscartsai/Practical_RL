{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[this demo requires doom installed either from gym-pool or from [ppaquette's repo](https://github.com/ppaquette/gym-doom)]\n",
    "\n",
    "## Basic Doom demo\n",
    "\n",
    "This demo solves DoomBasic env with a simple q-learning with experience replay.\n",
    "\n",
    "Video observation forces you to use ```CNN```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cpu, floatX=float32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=device=cpu, floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-21 08:27:31,462] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ppaquette_gym_doom\n",
    "from gym.wrappers import SkipWrapper\n",
    "from ppaquette_gym_doom.wrappers.action_space import ToDiscrete\n",
    "from agentnet.experiments.openai_gym.wrappers import PreprocessImage\n",
    "GAME_NAME = 'ppaquette/DoomBasic-v0'\n",
    "\n",
    "make_env = lambda: PreprocessImage(SkipWrapper(4)(ToDiscrete(\"minimal\")(gym.make(GAME_NAME))),\n",
    "                                   width=80,height=80,grayscale=True)\n",
    "\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation shape: (1, 80, 80)\n",
      "n_action: 4\n"
     ]
    }
   ],
   "source": [
    "#global params.\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "SEQ_LENGTH = 10\n",
    "FRAME_NUMBER = 4\n",
    "print(\"observation shape:\", observation_shape)\n",
    "print(\"n_action:\", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.0 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4012cfad68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f401ee9c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs, r, done, _ = env.step(1)\n",
    "print(r, done)\n",
    "plt.imshow(obs[0], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cpu, floatX=float32\n"
     ]
    }
   ],
   "source": [
    "#setup and import theano/lasagne. Prefer GPU\n",
    "%env THEANO_FLAGS=device=cpu, floatX=float32\n",
    "\n",
    "import theano, lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "from agentnet.memory import WindowAugmentation, LSTMCell\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "from agentnet.target_network import TargetNetwork\n",
    "from agentnet.experiments.openai_gym.pool import EnvPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of observation layer (None, 1, 80, 80)\n",
      "shape of prev wnd (None, 4, 1, 80, 80)\n",
      "reshape to (-1, 4, 80, 80)\n"
     ]
    }
   ],
   "source": [
    "#observation\n",
    "observation_layer = InputLayer((None,)+observation_shape,)\n",
    "print(\"shape of observation layer\", (None,)+observation_shape)\n",
    "\n",
    "#4-tick window over images\n",
    "prev_wnd = InputLayer((None, FRAME_NUMBER)+observation_shape)\n",
    "print(\"shape of prev wnd\", (None, FRAME_NUMBER)+observation_shape)\n",
    "new_wnd = WindowAugmentation(observation_layer, prev_wnd)\n",
    "        \n",
    "#reshape to (frame, h,w). If you don't use grayscale, 4 should become 12.\n",
    "wnd_reshape = reshape(new_wnd, (-1, FRAME_NUMBER*observation_shape[0])+observation_shape[1:])\n",
    "print(\"reshape to\", (-1, FRAME_NUMBER*observation_shape[0])+observation_shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define your NN which probably solve the environment. \n",
    "\n",
    "#### Tips:\n",
    "1. Main component are likely to be ```Conv2D``` and ```Pool2DLayer```\n",
    "2. Batch normalization here might speeds up training but may get unstable if you use small experience replay buffer\n",
    "3. Last layers should be Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.nonlinearities import elu, tanh, softmax\n",
    "net = {}\n",
    "net['conv1_1'] = Conv2DLayer(wnd_reshape, 32, 3, pad=1)\n",
    "net['conv1_2'] = Conv2DLayer(net['conv1_1'], 32, 3, pad=1)\n",
    "net['pool1'] = Pool2DLayer(net['conv1_2'], 2)\n",
    "net['conv2_1'] = Conv2DLayer(net['pool1'], 32, 3, pad=1)\n",
    "net['conv2_2'] = Conv2DLayer(net['conv2_1'], 32, 3, pad=1)\n",
    "net['pool2'] = Pool2DLayer(net['conv2_2'], 2)\n",
    "dense = DenseLayer(net['pool2'], num_units=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline for all qvalues\n",
    "qvalues_layer = DenseLayer(dense, num_units=n_actions, nonlinearity=None, name='qval')\n",
    "        \n",
    "#sample actions proportionally to policy_layer\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetnet = TargetNetwork(qvalues_layer)\n",
    "qvalues_old = targetnet.output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(qvalues_layer, qvalues_old),\n",
    "              agent_states={new_wnd: prev_wnd},\n",
    "              action_layers=action_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, W, b, W, b, W, b, qval.W, qval.b]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-21 08:27:32,837] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "pool = EnvPool(agent,\n",
    "               make_env, \n",
    "               n_games=1, #parallel games (only 1 so far)\n",
    "               max_size=1000) #experience replay pool holding last 1k sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 1 1 1 0]]\n",
      "[[ -5.  -5.  -5. -10.  -5.  -5.   0.]]\n",
      "CPU times: user 230 ms, sys: 430 ms, total: 660 ms\n",
      "Wall time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_, action_log, reward_log, _, _, _ = pool.interact(7)\n",
    "\n",
    "print(action_log)\n",
    "print(reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(64, replace=True)\n",
    "\n",
    "_, _, _, _, (qvalues_seq, old_qvalues_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      qvalues_target=old_qvalues_seq,\n",
    "                                                      gamma_or_gammas=0.99)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adam(loss,\n",
    "                               weights,\n",
    "                               learning_rate=0.0001)\n",
    "\n",
    "train_step = theano.function([], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-21 08:27:46,299] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-08-21 08:27:46,317] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-08-21 08:27:46,801] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.0.407.video000000.mp4\n",
      "[2017-08-21 08:27:49,879] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.0.407.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-21 08:28:08,435] Starting new video recorder writing to /notebooks/week4/records/openaigym.video.0.407.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-350.0\n",
      "Episode finished after 70 timesteps with reward=-350.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-21 08:28:14,766] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-350.0\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0)\n",
    "untrained_reward = np.mean(pool.evaluate(save_path=\"./records\", record_video = True, n_games=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {0: untrained_reward}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have ```tqdm```, remove the first line and ```tqdm_notebook``` from second line\n",
    "\n",
    "Loop may take years to finish.\n",
    "\n",
    "You may consider interrupting early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10\tepsilon=0.954\treward/step=-3.47273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6dadc4a7fac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtargetnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "\n",
    "for i in range(2000):  \n",
    "   \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH, append=True)\n",
    "    \n",
    "    loss = train_step()\n",
    "    \n",
    "    targetnet.load_weights(0.01)\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 0.05 + 0.95*np.exp(-epoch_counter/200.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter%10==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%100 ==0:\n",
    "        rewards[epoch_counter] = pool.evaluate(record_video=False)\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time,rw = zip(*sorted(list(rewards.items()),key=lambda p:p[0]))\n",
    "plt.plot(time,map(np.mean,rw))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=20,save_path=\"./records\",record_video=True)\n",
    "print(\"mean session score=%f.5\"%np.mean(rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save,load\n",
    "#save for display\n",
    "#save(action_layer,\"doombasic_dqn_2000.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "from random import choice\n",
    "#select the one you want\n",
    "videos = filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\"))\n",
    "video_path=\"./records/\"+choice(videos)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework II\n",
    "Get it work. We want stable positive score :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus assignment II\n",
    "* Better env\n",
    "  * Switch to DoomDefendCenter, DoomHealthGathering, DoomDeathmatch __or__ any atari game you want.\n",
    "  * Try to get `better_than_random` score on any of those environments __(2+++ pts)__\n",
    "  * Deploy a better network. Doom will likely need some recurrent netsle\n",
    "     * Find an arcitecture which maxsimizes score __(bonus points depend on your ```mean_reward```)__  \n",
    "     * Bonus can get large as you approach state-of-the-art\n",
    "     \n",
    "* Deploy a different RL algorithm\n",
    "  * Try at least two RL algorithms which had been learned during the course and try to compare them on ```mean_reward``` with similar training time (**plot** or **table** would be good idea) __(3 pts)__\n",
    "  * See the note in assignment 4.1 on how to train on-policy\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
