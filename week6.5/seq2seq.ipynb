{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Problem & Dataset\n",
    "\n",
    "* Chemistry is not a mostly loved subject.\n",
    "* There are various chemical compounds. The problem here is to pronounce a common name knowing its formula.  \n",
    "* So, we try to learn transition: molecular_formula->common_name.\n",
    "* If you want, you can replace source and target variables to predict something else (sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_name</th>\n",
       "      <th>molecular_formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethyl 3-ethoxy-2-nitroacrylate</td>\n",
       "      <td>C_{7}H_{11}NO_{5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N-Butyl-3-(4-fluorophenyl)-1-phenyl-1H-pyrazol...</td>\n",
       "      <td>C_{20}H_{20}FN_{3}O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N-Butyl-N-sec-butyl-1-benzothiophene-3-carboxa...</td>\n",
       "      <td>C_{17}H_{23}NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-{6-[(2S)-2-Butanyl]-2-(2-methyl-2-propanyl)-...</td>\n",
       "      <td>C_{21}H_{29}N_{5}O_{3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-Bromo-5-[(3-hydroxy-2,3-dimethyl-2-butanyl)a...</td>\n",
       "      <td>C_{13}H_{22}BrN_{3}O_{2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         common_name         molecular_formula\n",
       "0                     Ethyl 3-ethoxy-2-nitroacrylate         C_{7}H_{11}NO_{5}\n",
       "1  N-Butyl-3-(4-fluorophenyl)-1-phenyl-1H-pyrazol...       C_{20}H_{20}FN_{3}O\n",
       "2  N-Butyl-N-sec-butyl-1-benzothiophene-3-carboxa...           C_{17}H_{23}NOS\n",
       "3  2-{6-[(2S)-2-Butanyl]-2-(2-methyl-2-propanyl)-...    C_{21}H_{29}N_{5}O_{3}\n",
       "4  4-Bromo-5-[(3-hydroxy-2,3-dimethyl-2-butanyl)a...  C_{13}H_{22}BrN_{3}O_{2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecules = pd.read_csv('molecules.tsv', sep='\\t', index_col=0)\n",
    "molecules = molecules[[\"common_name\", \"molecular_formula\"]]\n",
    "molecules = molecules.dropna()\n",
    "print(len(molecules))\n",
    "molecules.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xy(x, y):\n",
    "    global molecules\n",
    "    return x.values, y.apply(lambda s: [\"START\"]+list(s)+[\"END\"])\n",
    "\n",
    "source_seqs, target_seqs = get_xy(molecules.molecular_formula, molecules.common_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_{7}H_{11}NO_{5} : Ethyl 3-ethoxy-2-nitroacrylate\n",
      "C_{20}H_{20}FN_{3}O : N-Butyl-3-(4-fluorophenyl)-1-phenyl-1H-pyrazole-5-carboxamide\n",
      "C_{17}H_{23}NOS : N-Butyl-N-sec-butyl-1-benzothiophene-3-carboxamide\n",
      "C_{21}H_{29}N_{5}O_{3} : 2-{6-[(2S)-2-Butanyl]-2-(2-methyl-2-propanyl)-5,8-dioxo-5,6,7,8-tetrahydro-4H-pyrazolo[1,5-a]pyrrolo[3,4-d]pyrimidin-4-yl}-N-cyclopropylacetamide\n",
      "C_{13}H_{22}BrN_{3}O_{2} : 4-Bromo-5-[(3-hydroxy-2,3-dimethyl-2-butanyl)amino]-2-propyl-3(2H)-pyridazinone\n"
     ]
    }
   ],
   "source": [
    "for source, target in zip(source_seqs[:5],target_seqs[:5]):\n",
    "    print(source, ':', \"\".join(target[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(source_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_letters = list(set([token for ts in target_seqs for token in ts]))\n",
    "target_letter_to_ix = {ph: i for i, ph in enumerate(target_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_letters = list(set([token for word in source_seqs for token in word]))\n",
    "source_letter_to_ix = {l: i for i, l in enumerate(source_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18901d6898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(list(map(len, target_seqs)), bins=25);\n",
    "\n",
    "# Truncate names longer than MAX_LEN characters. This can be changed\n",
    "MAX_LEN = min([150, max(list(map(len, target_seqs)))])\n",
    "print(MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into matrix of int32. Pad with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences, token_to_i, max_len=None, PAX_ix=-1):\n",
    "    \"\"\"\n",
    "    Converts several sequences of tokens to a matrix, edible a neural network.\n",
    "    Crops at max_len(if given), pads shorter sequences with -1 or PAD_ix.\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len, sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences), max_len), dtype='int32') -1\n",
    "    for i, seq in enumerate(sequences):\n",
    "        \n",
    "        row_ix = [token_to_i.get(_, 0) for _ in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44 11 24 17  2 38 11 24  8  8  2 10 30 11 24 19  2 -1 -1]\n",
      " [44 11 24 43 41  2 38 11 24 43 41  2 40 10 11 24 25  2 30]\n",
      " [44 11 24  8 17  2 38 11 24 43 25  2 10 30 36 -1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(as_matrix(source_seqs[:3], source_letter_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence', 'int32')\n",
    "target_sequence = T.matrix('target sequence', 'int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN\n",
    "\n",
    "You will be building a model that takes token sequence and predicts next token\n",
    "\n",
    "\n",
    "* Input sequence\n",
    "* One-hot / embedding\n",
    "* Encoder recurrent layer(s)\n",
    "* Decoder recurrent layer(s)\n",
    "* Softmax layer to predict probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 32\n",
    "HIDDEN_SIZE = 64\n",
    "\n",
    "##ENCODER\n",
    "l_in = InputLayer(shape=(None, None), input_var=input_sequence)\n",
    "l_mask = InputLayer(shape=(None, None), input_var=T.neq(input_sequence, -1)) \n",
    "\n",
    "l_emb = EmbeddingLayer(l_in, len(source_letters), EMBEDDING_SIZE)\n",
    "l_rnn = LSTMLayer(l_emb, \n",
    "                  HIDDEN_SIZE, \n",
    "                  only_return_final=True, \n",
    "                  mask_input=l_mask, \n",
    "                  grad_clipping=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DECODER\n",
    "dec_in = InputLayer(shape=(None, None), input_var=target_sequence)\n",
    "dec_mask = InputLayer(shape=(None, None), input_var=T.neq(target_sequence, -1))\n",
    "\n",
    "dec_emb = EmbeddingLayer(dec_in, len(target_letters), EMBEDDING_SIZE)\n",
    "dec_rnn = LSTMLayer(dec_emb, \n",
    "                    HIDDEN_SIZE,\n",
    "                    cell_init=l_rnn,\n",
    "                    mask_input=dec_mask, \n",
    "                    grad_clipping=5.)\n",
    "# WARNING! if it's lstm use cell_init, not hid_init\n",
    "\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "dec_rnn_flat = reshape(dec_rnn, (-1, dec_rnn.output_shape[-1]))\n",
    "\n",
    "decoder_flat = DenseLayer(dec_rnn_flat,\n",
    "                          num_units=len(target_letters),\n",
    "                          nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model weights\n",
    "weights = get_all_params(decoder_flat, trainable=True)\n",
    "#print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder = reshape(decoder_flat,\n",
    "                  [target_sequence.shape[0], target_sequence.shape[1], -1])\n",
    "#If you use dropout do not forget to create deterministic version for evaluation\n",
    "decoder_output = get_output(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_flat = decoder_output[:, :-1, :].reshape([-1, len(target_letters)])\n",
    "targets = target_sequence[:, 1:].ravel()\n",
    "targets_one_hot = lasagne.utils.one_hot(targets, len(target_letters))\n",
    "\n",
    "#do not count loss for '-1' tokens\n",
    "mask = T.neq(targets, -1).ravel()\n",
    "\n",
    "loss = T.dot(mask, T.nnet.categorical_crossentropy(predictions_flat, targets_one_hot))/T.sum(mask)\n",
    "\n",
    "updates = lasagne.updates.adam(loss, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "train = theano.function([input_sequence, target_sequence], \n",
    "                        loss, \n",
    "                        updates=updates, \n",
    "                        allow_input_downcast=True)\n",
    "\n",
    "#computing loss without training\n",
    "compute_cost = theano.function([input_sequence, target_sequence],\n",
    "                               loss, \n",
    "                               allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "\n",
    "We now need to implement a function that generates output sequence given input.\n",
    "\n",
    "Such function must work thusly:\n",
    "```\n",
    "Init:\n",
    "x = input\n",
    "y = [\"START\"]\n",
    "\n",
    "While not_too_long:\n",
    "  p(y_next|x,y) = probabilities of next letter for y\n",
    "  \n",
    "  y_next ~ p(y_next|x,y)\n",
    "  \n",
    "  y.append(y_next)\n",
    "  \n",
    "  if y_next == \"END\":\n",
    "      break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the function that computes probabilities for next token given previous text.\n",
    "# <network output reshaped to [batch,tick,token] format>\n",
    "\n",
    "# <a matrix [batch_i, decoder_n_tokens] of network output for last time step>\n",
    "last_word_probas = decoder_output[:, -1, :]\n",
    "\n",
    "# <a function that predicts probabilities coming after the last token>\n",
    "probs = theano.function([input_sequence, target_sequence], \n",
    "                        last_word_probas,\n",
    "                        allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_output(seq_in,\n",
    "                    output_prefix = (\"START\",),\n",
    "                    END_token=\"END\",\n",
    "                    temperature=1,\n",
    "                    sample=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement a function that generates output sequence given input.\n",
    "    \n",
    "    We recommend (but not require) you to use the pseudo-code above and inline instructions.\n",
    "    \"\"\"\n",
    "    \n",
    "    output = list(output_prefix)\n",
    "    \n",
    "    while True:\n",
    "        next_y_probs = probs(as_matrix([seq_in], source_letter_to_ix), \n",
    "                             as_matrix([output], target_letter_to_ix))\n",
    "        next_y_probs = next_y_probs**(1/temperature)\n",
    "        next_y_probs = next_y_probs/np.sum(next_y_probs)\n",
    "\n",
    "        if sample:\n",
    "            next_y = np.random.choice(target_letters, p=next_y_probs[0])\n",
    "        else:\n",
    "            next_y = target_letters[np.argmax(next_y_probs[0])]\n",
    "        \n",
    "        next_y = str(next_y)\n",
    "        assert type(next_y) is str, \"please return token(string/character), not it's index\"\n",
    "        \n",
    "        output.append(next_y)\n",
    "\n",
    "        if next_y == END_token:\n",
    "            break\n",
    "            \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_seqs = np.array(source_seqs)\n",
    "target_seqs = np.array(target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(source_seqs, target_seqs, batch_size):\n",
    "    \"\"\"samples a random batch of source and target sequences, batch_size elements\"\"\"\n",
    "    batch_ix = np.random.randint(0, len(source_seqs), size=batch_size)\n",
    "    source_seqs_batch=as_matrix(source_seqs[batch_ix], source_letter_to_ix) \n",
    "    target_seqs_batch=as_matrix(target_seqs[batch_ix], target_letter_to_ix)\n",
    "    \n",
    "    return source_seqs_batch, target_seqs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8377d5bcd44289af4e5bc2a71eb6cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14de2ce3cc2b4ba2a373b6b56fd25b28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 average loss = 2.737534108818424\n",
      "C_{24}H_{28}N_{4}O_{5} :\n",
      "N-(4S-hetarroamenyr-2-(5-pemibonyl-9Hpyrmutnylbo4-[2]smuamop-zenzoxyl)[2)ipmolfolo-4pyra1amidanod]o-3-adinolacroacylyn}-betlinanenydibidiquol6am\n",
      "C_{14}H_{18}ClNO_{3}S :\n",
      "3-([1-2,Axpeta 4-N-h-minerro-1]enaln-pyl)-4-(,3[3,bo{2-menbaxoxo-4-1-yl]2-dino-dihaatlolocetyl)hanamime\n",
      "C_{14}H_{16}N_{4}O_{3} :\n",
      "M(6,3-(3-B-3-hethoxeyn]{N-5,2-zelyl)-3-N-2-s\n",
      "C_{22}H_{16}N_{2}O_{6} :\n",
      "3-[3-{(3-(fmethy-3S-{4-(-3-methyl]-3Hethyl)-2-[3-(4H-broploneno]-1-1-nyrol)petuylbe\n",
      "C_{14}H_{18}ClNO_{2} :\n",
      "3-,N-R[3-Ey1]-Bennylethyl)3-(4-3H-methyr-2-phunoxylaminocy]bethylzox-2,,1]bfzenalophoabul]ulxenei6itlopide\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea31fe5bd49741cc8aee63d732add72d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "#total N iterations\n",
    "n_epochs=100\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "for epoch in tqdm_notebook(range(n_epochs)):\n",
    "\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in tqdm_notebook(range(batches_per_epoch)):\n",
    "        \n",
    "        x, y = sample_batch(source_seqs, target_seqs, batch_size)\n",
    "        avg_cost += train(x, y).mean()\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "    for i in range(5):\n",
    "        ind = np.random.randint(len(source_seqs))\n",
    "        print(source_seqs[ind], ':')\n",
    "        print(''.join(generate_output(source_seqs[ind], sample=True)[1:-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(generate_output(\"C_{7}H_{11}NO_{5}\", temperature=2)[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework part 2 - chemistry (6 pt total)\n",
    "\n",
    "* [4pts] Complete notebook and make sure target sequence is being generated.\n",
    "* [2pts] Modify train cycle to output sequences with different sampling strategies (varying t in range $[0, + \\infty)$ and try to find out which sampling strategy is the best for current task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [bonus] [2pts]  Latex display\n",
    "Swap target and source and learn name->formula, then try to reach quality when almos any generated sequence is a valid Latex formula and implement its prinitng using IPython magic in jupyter. It would be good if you create a demo and pass there some chemical (or not?) names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "z = IPython.display.Latex(data='$2+2$')\n",
    "IPython.display.display(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now,\n",
    "* try lstm/gru\n",
    "* try several layers\n",
    "* try mtg cards\n",
    "* try your own dataset of any kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.arange(-1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasagne.utils.one_hot(x, 10).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
