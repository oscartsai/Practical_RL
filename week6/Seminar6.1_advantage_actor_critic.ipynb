{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantage actor-critic in AgentNet (5 pts)\n",
    "\n",
    "Once we're done with REINFORCE, it's time to proceed with something more sophisticated.\n",
    "The next one in line is advantage actor-critic, in which agent learns both policy and value function, using the latter to speed up learning.\n",
    "\n",
    "Your main objective for this session is to... beat MountainCar-v0... with actor-critic.\n",
    "\n",
    "Beating means making submission to [gym leaderboard](https://gym.openai.com/envs/MountainCar-v0).\n",
    "\n",
    "``` MountainCar-v0 defines \"solving\" as getting average reward of -110.0 over 100 consecutive trials. ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n",
      "Starting virtual X frame buffer: Xvfb.\n",
      "env: DISPLAY=:1\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS='floatX=float32'\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1\n",
    "        \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:20:56,736] Making new env: MountainCar-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41727903  0.        ]\n",
      "n_actions: 3\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "obs = env.reset()\n",
    "state_size = len(obs)\n",
    "n_actions = env.action_space.n\n",
    "print(obs)\n",
    "print(\"n_actions:\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using shallow neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer, batch_norm, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observation_layer = InputLayer((None, state_size))\n",
    "\n",
    "#<your architecture>\n",
    "h1 = lasagne.layers.DenseLayer(observation_layer,\n",
    "                               num_units=256,\n",
    "                               nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "h2 = lasagne.layers.DenseLayer(h1,\n",
    "                               num_units=128,\n",
    "                               nonlinearity=lasagne.nonlinearities.rectify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "policy_layer = lasagne.layers.DenseLayer(h2,\n",
    "                                         num_units=n_actions,\n",
    "                                         nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "V_layer = lasagne.layers.DenseLayer(h2,\n",
    "                                    num_units=1,\n",
    "                                    nonlinearity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = theano.shared(np.float32(0.0), allow_downcast=True)\n",
    "policy_smooth_layer = NonlinearityLayer(policy_layer,\n",
    "                                        lambda p: (1. - eps) * p + eps / n_actions)\n",
    "\n",
    "#To pick actions, we use an epsilon-greedy resolver (epsilon is a property)\n",
    "from agentnet.resolver import ProbabilisticResolver\n",
    "action_layer = ProbabilisticResolver(policy_smooth_layer,\n",
    "                                     name=\"e-greedy action picker\",\n",
    "                                     assume_normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(policy_layer, V_layer),\n",
    "              action_layers=action_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, W, b, W, b]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params((action_layer, V_layer), trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:20:57,141] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,144] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,146] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,148] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,149] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,151] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,153] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,154] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,156] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,157] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,159] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,161] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,163] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,165] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,166] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,168] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,169] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,171] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,174] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,175] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,178] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,180] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,182] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,183] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,185] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,187] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,189] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,191] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,193] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,196] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,198] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,199] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,201] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,203] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,205] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,207] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,209] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,211] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,213] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,214] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,215] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,217] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,218] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,220] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,223] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,225] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,227] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,228] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,230] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,231] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,233] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,235] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,236] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,238] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,239] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,280] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,281] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,282] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,284] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,285] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,287] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,289] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,290] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:20:57,292] Making new env: MountainCar-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "#create a small pool with 10 parallel agents\n",
    "pool = EnvPool(agent, \"MountainCar-v0\", n_games=64, max_size=15000) \n",
    "\n",
    "#we assume that pool size 1000 is small enough to learn \"almost on policy\" :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 1 1 2 0 0]\n",
      " [0 0 2 2 2 1 1]\n",
      " [0 2 1 1 2 0 0]]\n",
      "[[-1. -1. -1. -1. -1. -1.  0.]\n",
      " [-1. -1. -1. -1. -1. -1.  0.]\n",
      " [-1. -1. -1. -1. -1. -1.  0.]]\n",
      "CPU times: user 20 ms, sys: 10 ms, total: 30 ms\n",
      "Wall time: 20.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_, action_log, reward_log, _, _, _ = pool.interact(7)\n",
    "\n",
    "print(action_log[:3])\n",
    "print(reward_log[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 10\n",
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor-critic loss\n",
    "\n",
    "Here we define obective function for actor-critic (one-step) RL.\n",
    "\n",
    "* We regularize policy with expected inverse action probabilities (discouraging very small probas) to make objective numerically stable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(128)\n",
    "\n",
    "_, _, _, _,(policy_seq, V_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentnet.learning import a2c                                                   \n",
    "\n",
    "elwise_mse_loss = a2c.get_elementwise_objective(policy_seq,\n",
    "                                                V_seq[:, :, 0],\n",
    "                                                replay.actions[0],\n",
    "                                                replay.rewards,\n",
    "                                                replay.is_alive,\n",
    "                                                gamma_or_gammas=0.99,\n",
    "                                                n_steps=1)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()\n",
    "loss += 0.01 * (1. / policy_seq).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<regularize agent with negative entropy. Higher entropy = smaller loss. Multiply by small coefficient>\n",
    "#loss += 1e-3 * T.mean(T.sum(policy_seq*T.log(policy_seq), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "#<your favorite optimization method>\n",
    "updates = lasagne.updates.rmsprop(loss, weights, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "[2017-10-03 01:21:01,483] We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    }
   ],
   "source": [
    "train_step = theano.function([], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:21:04,549] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:21:04,557] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-10-03 01:21:04,564] Starting new video recorder writing to /notebooks/week6/records/openaigym.video.0.975.video000000.mp4\n",
      "[2017-10-03 01:21:06,908] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 200 timesteps with reward=-200.0\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\", record_video=True)\n",
    "\n",
    "#video is in the ./records folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/10000 [00:21<36:34,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\treward/step=-0.99762\tloss ma=19.78468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 200/10000 [00:43<36:13,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=200\treward/step=-0.99762\tloss ma=19.69263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 300/10000 [01:05<34:52,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=300\treward/step=-0.99739\tloss ma=19.77358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 400/10000 [01:27<34:01,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\treward/step=-0.99739\tloss ma=19.55072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 499/10000 [01:48<34:18,  4.62it/s][2017-10-03 01:22:55,610] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:22:55,613] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=500\treward/step=-0.99762\tloss ma=19.39235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:22:56,287] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      "  5%|▌         | 500/10000 [01:49<1:06:29,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 600/10000 [02:11<33:45,  4.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\treward/step=-0.99762\tloss ma=19.58169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 700/10000 [02:32<33:09,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\treward/step=-0.99753\tloss ma=19.68910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 800/10000 [02:54<33:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=800\treward/step=-0.99739\tloss ma=19.65603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 900/10000 [03:15<32:53,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\treward/step=-0.99739\tloss ma=18.86553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 999/10000 [03:37<32:29,  4.62it/s][2017-10-03 01:24:44,589] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:24:44,594] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\treward/step=-0.99762\tloss ma=19.37908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:24:45,179] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 10%|█         | 1000/10000 [03:38<59:07,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1100/10000 [04:00<32:42,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\treward/step=-0.99762\tloss ma=19.40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1200/10000 [04:22<31:47,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\treward/step=-0.99739\tloss ma=18.73780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1300/10000 [04:43<32:14,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1300\treward/step=-0.99739\tloss ma=19.21088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1400/10000 [05:05<31:17,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1400\treward/step=-0.99762\tloss ma=19.85541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1499/10000 [05:27<30:55,  4.58it/s][2017-10-03 01:26:34,544] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:26:34,549] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1500\treward/step=-0.99762\tloss ma=19.56484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:26:35,132] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 15%|█▌        | 1500/10000 [05:28<56:05,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1600/10000 [05:49<30:28,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1600\treward/step=-0.99753\tloss ma=19.27067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1700/10000 [06:12<32:19,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1700\treward/step=-0.99739\tloss ma=18.92389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1800/10000 [06:34<29:47,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1800\treward/step=-0.99739\tloss ma=19.26984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1900/10000 [06:55<29:07,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1900\treward/step=-0.99762\tloss ma=18.75282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1999/10000 [07:17<29:12,  4.57it/s][2017-10-03 01:28:24,498] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:28:24,503] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2000\treward/step=-0.99762\tloss ma=19.13521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:28:25,097] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 20%|██        | 2000/10000 [07:18<53:07,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2100/10000 [07:39<28:22,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2100\treward/step=-0.99739\tloss ma=18.77139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2200/10000 [08:01<28:23,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2200\treward/step=-0.99739\tloss ma=18.65465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2300/10000 [08:23<28:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2300\treward/step=-0.99762\tloss ma=15.46185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2400/10000 [08:44<27:30,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2400\treward/step=-0.99741\tloss ma=7.21635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2499/10000 [09:06<27:53,  4.48it/s][2017-10-03 01:30:14,041] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:30:14,046] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2500\treward/step=-0.99723\tloss ma=2.14842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:30:14,577] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 25%|██▌       | 2500/10000 [09:07<48:09,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -177.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2600/10000 [09:29<27:27,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2600\treward/step=-0.99693\tloss ma=0.69849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2700/10000 [09:52<27:57,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2700\treward/step=-0.99684\tloss ma=0.34638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2800/10000 [10:15<27:21,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2800\treward/step=-0.99674\tloss ma=0.16829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2900/10000 [10:38<29:20,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2900\treward/step=-0.99676\tloss ma=0.15229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2999/10000 [11:01<26:23,  4.42it/s][2017-10-03 01:32:08,354] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:32:08,360] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3000\treward/step=-0.99674\tloss ma=0.12393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:32:08,805] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 30%|███       | 3000/10000 [11:01<42:19,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -148.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3100/10000 [11:24<25:47,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3100\treward/step=-0.99671\tloss ma=0.10158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3200/10000 [11:47<25:24,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3200\treward/step=-0.99666\tloss ma=0.11273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3300/10000 [12:09<24:50,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3300\treward/step=-0.99664\tloss ma=0.16909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3400/10000 [12:32<24:55,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3400\treward/step=-0.99655\tloss ma=0.18138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3499/10000 [12:54<24:14,  4.47it/s][2017-10-03 01:34:01,774] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:34:01,779] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3500\treward/step=-0.99654\tloss ma=0.19018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:34:02,215] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 35%|███▌      | 3500/10000 [12:55<38:33,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -146.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3600/10000 [13:17<24:03,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3600\treward/step=-0.99641\tloss ma=0.26475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3700/10000 [13:40<24:16,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3700\treward/step=-0.99648\tloss ma=0.28205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3800/10000 [14:03<23:06,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3800\treward/step=-0.99639\tloss ma=0.29903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3900/10000 [14:25<23:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3900\treward/step=-0.99631\tloss ma=0.31788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3999/10000 [14:47<22:11,  4.51it/s][2017-10-03 01:35:54,975] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:35:54,980] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4000\treward/step=-0.99630\tloss ma=0.32052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:35:55,380] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 40%|████      | 4000/10000 [14:48<34:28,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -136.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4100/10000 [15:10<22:06,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4100\treward/step=-0.99622\tloss ma=0.34436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4200/10000 [15:33<21:54,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4200\treward/step=-0.99623\tloss ma=0.38923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4300/10000 [15:56<22:12,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4300\treward/step=-0.99619\tloss ma=0.34994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4400/10000 [16:19<21:08,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4400\treward/step=-0.99616\tloss ma=0.37234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4499/10000 [16:41<20:39,  4.44it/s][2017-10-03 01:37:49,040] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:37:49,045] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4500\treward/step=-0.99616\tloss ma=0.35983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:37:49,426] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 45%|████▌     | 4500/10000 [16:42<31:22,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -113.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4600/10000 [17:05<20:13,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4600\treward/step=-0.99606\tloss ma=0.32534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4700/10000 [17:27<19:54,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4700\treward/step=-0.99606\tloss ma=0.34475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4800/10000 [17:50<19:38,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4800\treward/step=-0.99608\tloss ma=0.37585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4900/10000 [18:12<19:09,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4900\treward/step=-0.99608\tloss ma=0.37871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4999/10000 [18:35<18:53,  4.41it/s][2017-10-03 01:39:42,565] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:39:42,569] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5000\treward/step=-0.99600\tloss ma=0.40043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:39:42,994] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 50%|█████     | 5000/10000 [18:36<29:43,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -140.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5100/10000 [18:58<18:30,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5100\treward/step=-0.99606\tloss ma=0.37555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5200/10000 [19:21<18:15,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5200\treward/step=-0.99601\tloss ma=0.39320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5300/10000 [19:44<17:50,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5300\treward/step=-0.99600\tloss ma=0.40032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5400/10000 [20:07<17:38,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5400\treward/step=-0.99605\tloss ma=0.40659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5499/10000 [20:30<17:05,  4.39it/s][2017-10-03 01:41:37,491] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:41:37,496] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5500\treward/step=-0.99600\tloss ma=0.38900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:41:37,926] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 55%|█████▌    | 5500/10000 [20:30<26:59,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -129.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5600/10000 [20:53<16:56,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5600\treward/step=-0.99603\tloss ma=0.34977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5700/10000 [21:16<16:21,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5700\treward/step=-0.99600\tloss ma=0.40109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5800/10000 [21:39<16:01,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5800\treward/step=-0.99605\tloss ma=0.37947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5900/10000 [22:02<15:35,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5900\treward/step=-0.99598\tloss ma=0.38501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5999/10000 [22:25<15:19,  4.35it/s][2017-10-03 01:43:32,361] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:43:32,368] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6000\treward/step=-0.99604\tloss ma=0.41547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:43:32,737] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 60%|██████    | 6000/10000 [22:25<22:56,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -119.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6100/10000 [22:48<14:48,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6100\treward/step=-0.99604\tloss ma=0.42441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 6200/10000 [23:11<14:31,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6200\treward/step=-0.99595\tloss ma=0.40440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6300/10000 [23:34<14:05,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6300\treward/step=-0.99604\tloss ma=0.40642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 6400/10000 [23:57<13:56,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6400\treward/step=-0.99604\tloss ma=0.39067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6499/10000 [24:19<13:22,  4.36it/s][2017-10-03 01:45:27,197] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:45:27,203] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6500\treward/step=-0.99609\tloss ma=0.41225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:45:27,588] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 65%|██████▌   | 6500/10000 [24:20<20:18,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -123.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6600/10000 [24:43<13:01,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6600\treward/step=-0.99605\tloss ma=0.40799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6700/10000 [25:06<12:37,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6700\treward/step=-0.99611\tloss ma=0.39165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6800/10000 [25:29<12:20,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6800\treward/step=-0.99606\tloss ma=0.46140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6900/10000 [25:52<11:58,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6900\treward/step=-0.99607\tloss ma=0.43693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6999/10000 [26:14<11:24,  4.39it/s][2017-10-03 01:47:22,215] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:47:22,219] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7000\treward/step=-0.99610\tloss ma=0.46796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:47:22,606] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 70%|███████   | 7000/10000 [26:15<17:19,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -128.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7100/10000 [26:38<11:02,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7100\treward/step=-0.99605\tloss ma=0.39777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 7200/10000 [27:01<10:43,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7200\treward/step=-0.99608\tloss ma=0.42207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7300/10000 [27:24<10:16,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7300\treward/step=-0.99605\tloss ma=0.45921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7400/10000 [27:47<09:55,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7400\treward/step=-0.99608\tloss ma=0.45183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 7499/10000 [28:10<09:32,  4.36it/s][2017-10-03 01:49:17,310] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:49:17,315] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7500\treward/step=-0.99612\tloss ma=0.42858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:49:17,706] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 75%|███████▌  | 7500/10000 [28:10<14:29,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -125.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7600/10000 [28:33<09:09,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7600\treward/step=-0.99611\tloss ma=0.46619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7700/10000 [28:56<08:51,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7700\treward/step=-0.99607\tloss ma=0.50559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7800/10000 [29:19<08:21,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7800\treward/step=-0.99607\tloss ma=0.45647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7900/10000 [29:42<07:59,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7900\treward/step=-0.99608\tloss ma=0.47403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 7999/10000 [30:05<07:40,  4.34it/s][2017-10-03 01:51:12,306] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:51:12,311] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8000\treward/step=-0.99612\tloss ma=0.56546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:51:12,710] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 80%|████████  | 8000/10000 [30:05<11:44,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -133.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8100/10000 [30:28<07:16,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8100\treward/step=-0.99607\tloss ma=0.50886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8200/10000 [30:51<06:53,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8200\treward/step=-0.99614\tloss ma=0.53176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8300/10000 [31:14<06:27,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8300\treward/step=-0.99607\tloss ma=0.54796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8400/10000 [31:37<06:07,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8400\treward/step=-0.99615\tloss ma=0.51935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8499/10000 [32:00<05:41,  4.40it/s][2017-10-03 01:53:07,354] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:53:07,359] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8500\treward/step=-0.99608\tloss ma=0.54995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:53:07,751] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 85%|████████▌ | 8500/10000 [32:00<08:41,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -125.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8600/10000 [32:23<05:20,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8600\treward/step=-0.99611\tloss ma=0.49253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8700/10000 [32:46<04:56,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8700\treward/step=-0.99610\tloss ma=0.52699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8800/10000 [33:09<04:34,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8800\treward/step=-0.99611\tloss ma=0.47049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8900/10000 [33:32<04:13,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8900\treward/step=-0.99609\tloss ma=0.47556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 8999/10000 [33:55<03:49,  4.37it/s][2017-10-03 01:55:02,465] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:55:02,470] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9000\treward/step=-0.99610\tloss ma=0.46716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:55:02,852] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 90%|█████████ | 9000/10000 [33:55<05:48,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -126.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9100/10000 [34:18<03:26,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9100\treward/step=-0.99617\tloss ma=0.50835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9200/10000 [34:41<03:02,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9200\treward/step=-0.99611\tloss ma=0.49336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9300/10000 [35:04<02:41,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9300\treward/step=-0.99604\tloss ma=0.41617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9400/10000 [35:27<02:17,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9400\treward/step=-0.99597\tloss ma=0.40816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 9499/10000 [35:50<01:55,  4.35it/s][2017-10-03 01:56:57,496] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:56:57,501] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9500\treward/step=-0.99604\tloss ma=0.48728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:56:57,906] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      " 95%|█████████▌| 9500/10000 [35:50<02:56,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -132.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9600/10000 [36:13<01:31,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9600\treward/step=-0.99610\tloss ma=0.53257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9700/10000 [36:36<01:08,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9700\treward/step=-0.99605\tloss ma=0.49695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9800/10000 [36:59<00:47,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9800\treward/step=-0.99603\tloss ma=0.50110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9900/10000 [37:22<00:22,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9900\treward/step=-0.99607\tloss ma=0.43211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9999/10000 [37:45<00:00,  4.37it/s][2017-10-03 01:58:52,688] Making new env: MountainCar-v0\n",
      "[2017-10-03 01:58:52,693] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10000\treward/step=-0.99601\tloss ma=0.48352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-03 01:58:53,069] Finished writing results. You can upload them to the scoreboard via gym.upload('/notebooks/week6/records')\n",
      "100%|██████████| 10000/10000 [37:46<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 20) = -125.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "loss = 0\n",
    "eps_val = 1.0\n",
    "for i in tqdm(range(10000)):\n",
    "    \n",
    "    eps_val *= 0.998\n",
    "    eps.set_value(eps_val)\n",
    "    \n",
    "    #train    \n",
    "    for _ in range(10):\n",
    "        pool.update(SEQ_LENGTH, append=True)\n",
    "    \n",
    "    for _ in range(10):\n",
    "        loss = loss * 0.99 + train_step() * 0.01\n",
    "\n",
    "    if epoch_counter % 100 == 0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = np.average(pool.experience_replay.rewards.get_value()[:,:-1],\n",
    "                                      weights=1+pool.experience_replay.is_alive.get_value()[:,:-1])\n",
    "        print(\"iter=%i\\treward/step=%.5f\\tloss ma=%.5f\" % (epoch_counter,\n",
    "                                                           pool_mean_reward,\n",
    "                                                           loss))\n",
    "        \n",
    "\n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter % 500 == 0:\n",
    "        n_games = 20\n",
    "        eps.set_value(0)\n",
    "        rewards[epoch_counter] = pool.evaluate(record_video=False,\n",
    "                                               n_games=n_games,\n",
    "                                               verbose=False)\n",
    "        \n",
    "        print(\"Current score(mean over %i) = %.3f\"%(n_games, np.mean(rewards[epoch_counter])))\n",
    "    \n",
    "    \n",
    "    epoch_counter += 1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters, session_rewards = zip(*sorted(rewards.items(), key=lambda k: k[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f730a49f198>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VOXd//H3NwsJgQBJgLAkbJFVUJYICXUXrWhVtG7U\nitW61dpqW3+t1i62te3TTevSVnnUuosrxcellLgvJBA2gQQEwpYACSSBQELWuX9/ZEIjJhAymcxM\n5vO6rrmY3OfMme/khHxyzn2f+5hzDhERCW8RgS5AREQCT2EgIiIKAxERURiIiAgKAxERQWEgIiIo\nDEREBIWBiIigMBARESAq0AW0Vd++fd2wYcMCXYaISMhYtmzZHudcv7asGzJhMGzYMHJzcwNdhohI\nyDCzrW1dV6eJREREYSAiIgoDERFBYSAiIigMREQEhYGIiKAwEBERFAbSxWUXlLKmaF+gyxAJegoD\n6bIaPI5bn1/O3f9aE+hSRIJeyFyBLHKsVm4vZ8+BWsoqa6morqNXbHSgSxIJWjoykC5rUV4JAB4H\nSzeXBbgakeCmMJAua1HeLk4alkC3qAgWbyoNdDkiQU2niaRLKth9gE27K7k6YyjRkRF8qjAQOSId\nGUiXlJVfDMCMcclkjkgif1cF5ZW1Aa5KJHgpDKRLWpRXzNiBvUhJiGP6cUk4BzmbdXQg0hqFgXQ5\npQdqWLa1nLPHJQNwQkof4rpFqt9A5AgUBtLlvLuuBI+Dc7xhEB0ZwUnDEtVvIHIECgPpchblFTOw\ndyzHD+p1qC0zLYkNJQfYvb8mgJWJBC+FgXQp1XUNfLRhDzPGJmNmh9qnpyUBsLhARwciLVEYSJfy\nycY9HKxrYIb3FFGT4wf1Jj42isWb9gSoMpHg5lMYmNllZrbWzDxmlt6s/WwzW2Zmq73/ntls2RRv\n+0Yze9Ca//km4qOs/GJ6xkSRMSLxC+2REca04Ukh14lcXddAdV1DoMuQMODrkcEa4BLgw8Pa9wAX\nOOcmANcAzzRb9g/gBmCk93GujzWIAODxOLLySzhtVD9ioiK/tDwzLYktpVXs2HswANUdu5r6Bi59\n5FOm/8+7PJu9lfoGT6BLki7MpzBwzuU759a30L7CObfD++VaoLuZxZjZQKCXcy7bOeeAp4FZvtQg\n0mRV4V527685NKT0cIf6DULk6OCBrA2sKapgYO9YfvavNZz/4Md8vEGnucQ/OqPP4OvAcudcDTAY\nKGy2rNDb1iIzu9HMcs0sd/fu3X4uU0LdorxiIiOMM0b3b3H56OR4Ent0C4khpsu2lvHIB5u4Ij2V\nN753Mo98czJVdfV88/Ecrn9qKQW7DwS6ROlijhoGZpZlZmtaeFzUhtceD/wBuKk9xTnn5jrn0p1z\n6f369WvPJiSMLMorZuqwRHrHtTxVdUSEkTEikeyCUhoPTINTZU09P3xpFYP6dOdnXxuLmXHu+IEs\n+sFp3DlzDNkFZZxz/4f85o089lXVBbpc6SKOOlGdc25GezZsZinAfGCOc26Tt7kISGm2Woq3TcQn\nW/ZUsqHkALOnDjnieplpfXlr9S62lVUxNKlHJ1V3bH7/dj7byqp44YYM4pvdgyE2OpKbT0vj65NT\nuG/Rep74ZDOvLS/kh2ePYvbUIURFanCgtJ9ffnrMrA/wJnCnc+6Tpnbn3E6gwswyvKOI5gAL/FGD\nhJemiela6y9okjkiuPsNPvh8N89mb+P6k4eT4a31cP3iY/j9JSfwxvdOZvSAeH6+YC0zH/iIDz/X\nqVRpP1+Hll5sZoVAJvCmmS30LroVOA74hZmt9D6aTuTeAjwGbAQ2AW/7UoMINJ4iGjMgntTEuCOu\nl9avB/3jY4Ky32BvVS0/fmUVo5J78qNzRh91/eMH9eaFGzJ49Oop1DZ4mPPEEq57cimb1J8g7eDT\n/Qycc/NpPBV0ePu9wL2tvCYXGO/L+4o0V15Zy9ItZXz3jOOOuq6ZkZmWxKebGvsNgukyl18sWEvp\ngVoev+YkYqO/PDS2JWbGV48fwOmj+/HUp1t46J2NfPX+D7k6cyi3nTWSPnHd/Fy1dBU6ySghr2li\nuhljj3yKqMn0tCR2768Jqr+g/2/VDl5ftYPbZ4xk/ODex/z6mKhIbjw1jff+3+lcflIqT326hdP/\n/D5PfbqFOl2fIG2gMJCQl5VfTHKvGCa08Zdo5oi+QPD0GxRXVPPzBWuYmNqHm09L82lbfXvG8LuL\nJ/Dm90/h+EG9+OXra7nw4U/YWLK/g6qVrkphICGtuq6BDz7fzVljk4mIaNspn9TE7gzu0z0o+g2c\nc/zk1c+ormvgvstP7LARQWMH9uLZb0/jkW9Oobiimgse+oQXl24L6iG1ElgKAwlpiwtKqaptOOoo\nouaa+g2yC0rxeAL7y/GFJdt5f/1ufnreWEb069mh2268PmEA/77tFCYP7cNPXl3NrS+sYN9BXZsg\nX6YwkJC2KK+YuG6Rh4aMttX0tCTKq+pYtytwp0+2llZy75t5nDKyL9+cNtRv79O/VyzPXDeNH587\nmn+v2cV5D3zEsq1lfns/CU0KAwlZHo/jnfxiThvVr82jb5pkBvj+Bg0ex49eWkVkhPHHS09o8ymu\n9oqIMG45/ThevjmTiAi4/NFsHn53Aw1+PjKqb/BQWx+4Duya+gY2luynqrY+YDX4orqugS17Kjvl\nvXwaWioSSKuL9lFc0frEdEcysHd3hvftweJNe/j2ycP9UN2Rzf2wgNyt5fz1iokM7N2909538pAE\n3vz+Kdw9fw1//s/nfLKxlPuvmMiA3rEd+j679lXzfM5Wnl+ynV6xUbx0cyZ9e8Z06Hsczb6DdVzx\n6OJDR39JPbqRkhhHSkJ3UhPiSE1s+jeOQX1iW5zpNpAqa+q58ZlcNhQf4N07TqdnjH9/XSsMJGQd\nbWK6o8kYkcQbq3ZQ3+Dp1Kkc8ndWcN+i9Zw3YQAXTRzUae/bpFdsNA9eOZFTR/blFwvWMvOBD/nT\npSd+6YZAx8o5R87mMp5evIWFa4vxOMepI/uRs7mUa55Ywrwbvzi9hj9V1zV4J/Sr5OdfG0dNfQPb\nyw5SWF7F2qJ9/GftLuoa/ntUZAbJ8bGHAiIlMY7UhO6kJsYxdmAvenfvnLqb7DtYx7X/XMLK7Xv5\n06Un+j0IQGEgISwrv5j0oQkk9GjfhVXT05J4Yck21u6o4MTUPh1cXctq6hv4wYsr6d29G/fOmhCw\ni97MjMvSU5k8NIHvPb+C65/O5VvTh3HnzDHHfMqtsqae+SuKeHrxFj4vPkCfuGiuP3k438wYSmpi\nHO+tL+GGp3K54elcnrx26jFv/1jVN3i49fnl5G4t5+HZkzn/hIFfWqfB4yiuqGZ7WRXbyw+yvayK\nwvKDbC+vIruglJ0ri2gaeNW7ezT/uGoy04/r69e6m5QeqOHqx5ewoWQ/f/vGZGZO+HL9/qAwkJC0\nvayKdbv287Pzx7Z7G01z/3y6qbTTwuCvWRtYt2s/j1+TTmI7Q6wjpfXryfzvTucPbzdOfJddUMrD\n35jEcf3jj/raTbsP8Mzirby6rJD9NfWMH9yLP156AheeOOgLv/DPGN2fP192Ire/uJLb5q3g71dN\nIdJPfSTOOX46fzVZ+SX85qLjWwwCaLzz3aA+3RnUpzvTWlheW+9hx96DbCmt5Hdv5XP1E0u454Jx\nXJ05zC91N9m1r5qrHsumsPwg/zsnndPbedTbHgoDCUmL8to2Md2R9IuPYVRyTxYXlPKd03272Kst\ncreU8egHm7jypFTOauPV0p0hJiqSX1wwjpNHJnHHy59xwUOfcM+F47g8PfVLRy4NHse760p4evEW\nPtqwh+hI4/wJA5kzfRiTUvu0eqQza9Jgyipr+fUbedw9fzW/v8Q/R0V/XLiel3ILue2skT794u4W\nFcGwvj0Y1rcHU4YmcPu8lfx8wVrWF+/nlxccT7QfTituK63iqsezKa+s4+nrpjLtGEfI+UphICFp\nUV4xo5J7+jwNdeaIJF7KLaS23kO3KP/1G1TW1POjl5vuUTDOb+/jizPHJPPv207hBy+t5CevrubD\nDXv43cUT6N09mrLKWl5cup1ns7dStPcgA3rFcsc5o7jipCH0i29bx/B1Jw+nrLKWh9/bSGKPbvz4\n3DEdWv/jH2/mH+9v4qppQ7h9xsgO2258bDRz56Tzx4XrePSDAjaVVPL3qya3+/RkSzaW7Oeqx3Ko\nrvPw3PXTOu1ItTmFgYScvVW1LNlSxk2njvB5W5lpfXlq8VY+K9xL+rDEDqiuZb97q/EeBfNuyOiU\nzsD2arom4ZEPN/GX/3zOym17mTY8kTdW76S23kPGiER+dv5Yzh6X3K5O9x+dM4qyqlr+/v4mEnt0\n4/pTfN+HAP9aUcRv3sjjvAkD+PVF4zv8qCMywrhr5lhGJ8dz56urmfX3T3hsTjojk49+Ou1o1hTt\nY84TS4gw48WbMhgzoFcHVHzsdJ2BhJz31++mweN8OkXUJGNEImb4dWqK99aX8FzONm44ZUSnH/q3\nx+HXJPx77S4uT0/hPz84lXk3ZjJzwsB2j74yM35z0Xhmjh/AvW/m89rywqO/6CjeW1/CHS+vInNE\nEvdfMdFv/REAl0xO4YUbM6isaeDiv3/Ke+tKfNresq1lzP7fbLpHR/LyzZkBCwJQGEgIWpRXTL/4\nGE5M8f1Quk9cN8YN7OW3Sev2VtXyk1c+Y1RyT3549ii/vIe/TB6SwAd3nMGKX5zNvbMmMKoD/gqG\nxr+y/3rlRKanJfH/XvmMd9cVt3tbK7aVc8uzyxk9IJ65c6Z0yrUCU4Ym8PqtX2FoUhzXPbWUuR9u\natecTx9v2MM3H1tC354xvHRzJsP7BvbOewoDCSk19Y0T080Y27/DrtrNHJHEsm3lVNc1dMj2mvvl\n62spq6zlvssn+n1IpT9ERJhffsHGREUyd0464wb24pbnlpO75dinx9hYsp9rn1xK/14xPHnt1E67\nhgFgUJ/uvHxzJjPHD+B3b63jjpc/o6a+7T8/i/KKue7JpQxNiuPFmzIY3KfzLjxsjcJAQkp2QRkH\naurbfO+Ctph+XBK19R6WbyvvsG0CfPj5bhas3MF3zziuXfco6Op6xkTx5LUnMah3d657cinrdlW0\n+bU79h5kzuNLiI6M4JnrprW5E7sjxXWL4uHZk7l9xkheXV7I7LnZlOyvPurrFqws4uZnlzF2UC/m\n3ZhB//iOvfq7vRQGElIW5e2ie3QkX+nAC4BOGpZIZIR16Kmi6roGfr5gDSP69uCWM/w/bDVUJfWM\n4elvT6V7t0jmPL6E7WVVR31NeWUtc55Ywv7qep66dipDko58q1N/iogwbp8xir99YzJ5OyuY9fAn\nrCna1+r685Zs4/YXV5I+NIHnrp8WVHeiUxhIyHDOkZVXwqmj+nboKZf42GgmDO7doWHw9/c3sbW0\nit/MGh90c94Em5SEOJ759jRq6j1c/XgOu/fXtLpuVW091z21lG1lVfzvNemMGxS4Dtfmzj9hIK/c\nPB0HXPbIYt5evfNL6zz2UQF3vraa00b148lrpwbdqDKFgYSMNUUV7Kqo7tBTRE2mpyWxcvteKmt8\nn91y0+4DPPL+JmZNHNShRzBd2ajkeJ741kkUV9TwrX8uoaL6y/dcqGvwcMtzy1m1fS8PXjnp0BXk\nwWL84N4suPUrjBkYz3eeW84DWRtwzuGc44GsDdz7Zj4zxw9g7tXpdO8WfH8gKAwkZCzKLybC4Mwx\nHX+JfmZaEvUeR+5W3/oNnHP8bP4aYqMjuPv84Ly4LFhNGZrAP745mfW79nPj07lf6ND3eBw/eeUz\n3l+/m99ePIFzxw8IYKWt6x8fyws3ZHDJpMHcn/U5tz6/gt++mc/9WZ/z9ckpPDR7kl8vbvRFcFYl\n0oJFecVMGZpAkh+mQk4fmkh0pPHppj0+bedfK4tYXFDKT2aOCUinZqg7fXR//nL5iWQXlHHbvBXU\nN3hwzvG7t/J5bUURd5wzitlThwS6zCOKjY7kL5efyF0zx/DWmp089vFm5mQO5U+XntCps+Meq+A6\naSXSisLyKvJ3VvDT8zp2CoMm3btFMik1wad+g31Vddz7Rj6ThvRh9knB/QsrmF00sXEeo1/9Xx53\nz1/DsL49eOzjzXxr+jC+e8ZxgS6vTcyMm05LY9ygXmwtreKqaUMCNkNtWykMJCRkHZqYzn+nBzLT\nknjo3Q3sO1jXrvnr/7BwHXsP1vHMrAl+v3NZV3ftVxrnMXro3Y0AXHDiIH7xtXFB/wv1cKeM7Mcp\nHTdNkl8F7zGLSDOL8otJ69fDr1dpZqYl4XGwZPOxXwC1bGs5z+ds49rpw4JmhEuo++HZo/jO6WnM\nmjiIv1x2ogLWz3RkIEFv38E6cgrKOmxSs9ZMGtKHmKgIFm8qPaZ5j+oaPNw9fzUDe8fygxCbciKY\nmRk/6eCZTaV1CgMJeu+vL6He4zh7nH9v9BETFUn6sIRj7kR+8pMtrNu1n0evnkKPIBs7LtJWOk0k\nQS8rv4S+PbsxMTXB7+81Pa0v63btp6yytk3rF+09yP1ZnzNjbH/O6YBZVEUCRWEgQa223sP760o4\nc0x/v05N3KTpQqbsgraNKvrV62txDu658PiQ69wUaU5hIEEtZ3Mp+2vq/TqKqLkTUnrTo1tkm4aY\nLsor5j95xdw2YyQpCYGbH0ekIygMJKhl5RUTGx3ByZ00rUN0ZAQnDU88ar9BZU09v1ywhtHJ8Xz7\n5OGdUpuIPykMJGgV7T3IayuKOG1Uv06dy2V6WhKbdldSUtH6dMQPvrOBHfuq+e3F4/1yc3SRzqaf\nYglK9Q0ebp+3Aufgp+eN7dT3zhzReBSyuJV+g3W7Knjs481ceVKqX++bLNKZFAYSlB5+byNLt5Rz\n76zxDE3q3NsBjhvUi16xUS32G3g8jrvnr6F392iNgZcuRWEgQWfpljIefGcDl0wazKxJgzv9/SMj\njGkjkvi0hTB4MXc7y7aW89PzxpLQI3huTCLiK4WBBJV9VXXc9sIKUhPj+PWs8QGrY3paEtvKqigs\n/++dt/YcqOF/3l7HtOGJfH1y54eUiD/5FAZmdpmZrTUzj5mlt7B8iJkdMLM7mrWda2brzWyjmd3p\ny/tL1+Kc4675n1Gyv4YHr5wU0DtBZaY1Xm/Q/FTR797Kp6q2nt9ePF7XFEiX4+uRwRrgEuDDVpbf\nB7zd9IWZRQJ/A2YC44DZZqY7gAgALy7dzlurd/Gjc0ZzYmqfgNYyqn88ST26HQqDTzft4bXlRdx0\nahrH9Y8PaG0i/uDTn17OuXygxb+SzGwWsBmobNY8FdjonCvwrjMPuAjI86UOCX0bSw7wq//L4yvH\nJXHTqf6dkK4tIiKMjBFJLC4opaa+gZ/9aw1DEuO49czQmE9f5Fj5pc/AzHoCPwF+ddiiwcD2Zl8X\netskjNXUN/D9F1YQGx3BfZdPDJqpijPTkti5r5qfvraGgt2V/Pqi44mNDr5714p0hKMeGZhZFtDS\nXAB3O+cWtPKye4D7nXMHfDm3amY3AjcCDBmiO0d1VX94ez15Oyt4/Jp0knvFBrqcQ5r6DV5dXsj5\nEwZy+mj/zpoqEkhHDQPn3Ix2bHcacKmZ/RHoA3jMrBpYBqQ2Wy8FKDrCe88F5gKkp6e7dtQhQe69\n9SU88UnjLQ3PGhtcs36O6NuD5F4xVNY08IsL1LUlXZtfhms4505pem5m9wAHnHMPm1kUMNLMhtMY\nAlcC3/BHDRL8SvZXc8dLqxgzIJ47ZwbfBVxmxu8vmUB0ZERQHbGI+INPYWBmFwMPAf2AN81spXPu\nq62t75yrN7NbgYVAJPCEc26tLzVIaPJ4HD96aRWVtfXMm50RtOfizxwTXEcrIv7i62ii+cD8o6xz\nz2FfvwW85cv7Suh7/OPNfLRhD7+9eDwjkzVUUyTQdAWydLrVhfv448J1nHv8AL4xVQMDRIKBwkA6\nVWVNPd+ft4K+PWP4n69P0JW8IkFCd++WTvXL19eypbSSF27IoE+cJnoTCRY6MpBO8/qqHbyyrJDv\nnXHcoXsNi0hwUBhIp9heVsXdr61mytAEvn/WyECXIyKHURiI39U3eLht3gow+OsVE4nSbSJFgo76\nDMTvHnhnA8u37eWh2ZNITYwLdDki0gL9iSZ+lV1QysPvbeSyKSlccOKgQJcjIq3QkYF0uAaP4+ON\ne5i3ZBuL8ooZntSDey48PtBlicgRKAykw+zYe5CXcrfzcm4hRXsPkhAXzbemD+O6k4fTI4B3LROR\no9P/UPFJXYOHd/JLmLd0Gx98vhvn4JSRfbnrvDGcPS6ZmKjgnHNIRL5IYSDtsnlPJfOWbuPVZYXs\nOVBLcq8Ybj3jOC5PT1UnsUgIUhhIm1XXNfD2mp3MW7KdnM1lREYYZ47pz+ypqZw6sp+GjIqEMIWB\nHFXejgpeXLqN+SuKqKiuZ2hSHD8+dzSXTk6hv+b5F+kSFAZyRD98aSWvLS+iW1QEM8cP4IqTUskY\nnhQ09ykWkY6hMJBWVVTX8a8VRcyaOIh7LjxeE8uJdGE6ySutyt1ShsfB5SelKghEujiFgbQqp6CM\nbpERTB6SEOhSRMTPFAbSquyCUiam9gna+xOLSMdRGEiL9lfXsWZHBdNGJAa6FBHpBAoDaVHu1nIa\nPI5pw3UTGpFwoDCQFuUUlBEdaUwe2ifQpYhIJ1AYSIuyC0o5IaUPcd00+lgkHCgM5Esqa+pZXbSP\nDPUXiIQNhYF8yTL1F4iEHYWBfEl2QSlREcaUobq+QCRcKAzkS3I2lzEhpbduSCMSRhQG8gVVtfWs\n2r6XjBE6RSQSThQG8gXLt+6l3uOYNlydxyLhRGEgX5BdUEpkhJE+TGEgEk4UBvIFOZtLGT+4Nz3V\nXyASVhQGcsjB2gZWbt9Lhk4RiYQdhYEcsmJbOXUNTp3HImFIYSCHZG8uI8IgfZiuLxAJNwoDOSS7\noLG/ID42OtCliEgnUxgIANV1jf0FGlIqEp4UBgLAim17qa33aD4ikTDlUxiY2WVmttbMPGaWftiy\nE8xssXf5ajOL9bZP8X690cweNDPzpQbpGDmbSzGDk3RkIBKWfD0yWANcAnzYvNHMooBngZudc8cD\npwN13sX/AG4ARnof5/pYg3SA7IJSxg3sRe/u6i8QCUc+hYFzLt85t76FRecAnznnVnnXK3XONZjZ\nQKCXcy7bOeeAp4FZvtQgvqupb2DFNs1HJBLO/NVnMApwZrbQzJab2Y+97YOBwmbrFXrbJIBWbd9H\nTb1HncciYeyocw6YWRYwoIVFdzvnFhxhuycDJwFVwDtmtgzYdyzFmdmNwI0AQ4YMOZaXyjHILmjs\nL5iqMBAJW0cNA+fcjHZstxD40Dm3B8DM3gIm09iPkNJsvRSg6AjvPReYC5Cenu7aUYe0Qc7mUsYM\n6EWfuG6BLkVEAsRfp4kWAhPMLM7bmXwakOec2wlUmFmGdxTRHKC1owvpBLX1HpZtLdf9jkXCnK9D\nSy82s0IgE3jTzBYCOOfKgfuApcBKYLlz7k3vy24BHgM2ApuAt32pQXzzWeFequt0fYFIuPNpnmLn\n3HxgfivLnqXxtNDh7bnAeF/eVzpOdkEpoP4CkXCnK5DDXM7mMsYMiCexh/oLRMKZwiCM1TV4yN1S\nriGlIqIwCGefFe7jYF2DLjYTEYVBOMvZrP4CEWmkMAhj2QVljEruSVLPmECXIiIBpjAIU3UNHpZt\nKdOQUhEBFAZha03RPipr1V8gIo0UBmEqZ3MZoP4CEWmkMAhT2QWlpPXrQb949ReIiMIgLNV7ry/Q\nKSIRaaIwCEN5Oys4UFPPNIWBiHgpDMJQ03xEGeovEBEvhUEYyikoY0TfHvTvFRvoUkQkSCgMwkyD\nx7Fkc5lOEYnIFygMwkz+zgr219TrZjYi8gUKgzDT1F+gK49FpDmFQZjJLihjWFIcA3qrv0BE/kth\nEEY8HsdSzUckIi1QGISR/F0V7DtYR0aa+gtE5IsUBmEkp6BxPiIdGYjI4RQGYSS7oJQhiXEM6tM9\n0KWISJBRGIQJj8exZEuZ7ncsIi1SGISJ9cX72VtVp8npRKRFCoMwkdN0fYEuNhORFigMwkR2QRkp\nCd1JSYgLdCkiEoQUBmHAuab+Ap0iEpGWKQzCwIaSA5RV1uoUkYi0SmEQBprmI8pU57GItEJhEAZy\nCsoY1DuWlARdXyAiLVMYdHHOOXI2l5IxIgkzC3Q5IhKkFAZd3KbdB9hzQP0FInJkCoMubrF3PiJd\nbCYiR6Iw6OJyCkoZ0CuWIYm6vkBEWqcw6MI8Hkd2QSkZIxLVXyAiR6Qw6MJWFu5lz4FazhjTP9Cl\niEiQUxh0YYvyiomKME4frTAQkSNTGHRhWXnFTBuRSO/u0YEuRUSCnE9hYGaXmdlaM/OYWXqz9mgz\ne8rMVptZvpnd1WzZuWa23sw2mtmdvry/tG7Lnko2lBxgxtjkQJciIiHA1yODNcAlwIeHtV8GxDjn\nJgBTgJvMbJiZRQJ/A2YC44DZZjbOxxqkBVn5xQAKAxFpkyhfXuycywdaGqnigB5mFgV0B2qBCmAq\nsNE5V+B93TzgIiDPlzrkyxblFTNmQDypGlIqIm3grz6DV4BKYCewDfizc64MGAxsb7ZeobetRWZ2\no5nlmlnu7t27/VRq11NeWUvu1nLOHqejAhFpm6MeGZhZFjCghUV3O+cWtPKyqUADMAhIAD7ybueY\nOOfmAnMB0tPT3bG+Ply9/3kJDR6nU0Qi0mZHDQPn3Ix2bPcbwL+dc3VAiZl9AqTTeFSQ2my9FKCo\nHduXI8jKK6F/fAwTBvcOdCkiEiL8dZpoG3AmgJn1ADKAdcBSYKSZDTezbsCVwOt+qiEs1dQ38P76\nEs4am0xEhK46FpG28XVo6cVmVghkAm+a2ULvor8BPc1sLY0B8E/n3GfOuXrgVmAhkA+85Jxb60sN\n8kXZBWVU1jZw9jhdaCYibefraKL5wPwW2g/QOLy0pde8Bbzly/tK67LyiukeHcn0tL6BLkVEQoiu\nQO5CnHNk5Rdz6qi+xEZHBrocEQkhCoMuZO2OCnbuq9YoIhE5ZgqDLmRRXjERBmdqllIROUYKgy4k\nK7+YKUNRBbrHAAAInElEQVQTSOoZE+hSRCTEKAy6iB17D7J2R4VOEYlIuygMuoh3miam0xQUItIO\nCoMu4j95xYzo24O0fj0DXYqIhCCFQRewv7qO7IJSTUwnIu2mMOgCPvx8D3UNTqeIRKTdFAZdQFZ+\nMQlx0UwekhDoUkQkRCkMQlxdg4d315Vw5phkIjUxnYi0k8IgxOVuKWffwTr1F4iITxQGIS4rv5hu\nURGcMlIT04lI+ykMQljTxHRfSUuiR4xPE9CKSJhTGISwDSUH2FpapVFEIuIzhUEIW5TnvepYU1CI\niI8UBiEsK7+YE1N6k9wrNtCliEiIUxiEqJL91azcvldHBSLSIRQGIerd/BKc08R0ItIxFAYhKiu/\nmJSE7owZEB/oUkSkC1AYhKCDtQ18tGEPM8YmY6arjkXEdwqDEPTxxj3U1Ht01bGIdBiFQQhalLeL\n+Ngopg5PDHQpItJFKAxCTIPH8U5+CWeM7k90pHafiHQM/TYJMSu376W0slajiESkQykMQkxWfjFR\nEcZpo/oFuhQR6UIUBiEmK6+YaSMS6d09OtCliEgXojAIIVv2VLKh5ABn66pjEelgCoMQkpXfODHd\nWQoDEelgCoMQsiivmDED4klNjAt0KSLSxSgMQkR5ZS25W8t1oZmI+IXCIES8t76EBo9TGIiIXygM\nQkRWfjHJvWIYP6h3oEsRkS5IYRACauob+GD9bs4am0xEhCamE5GOpzAIAdkFZVTWNmhIqYj4jcIg\nBCzK20Vct0gy05ICXYqIdFE+hYGZ/cnM1pnZZ2Y238z6NFt2l5ltNLP1ZvbVZu3nets2mtmdvrx/\nOHDOkZVXwqkj+xEbHRnockSki/L1yGARMN45dwLwOXAXgJmNA64EjgfOBf5uZpFmFgn8DZgJjANm\ne9eVVqzdUcGuimpNTCcifuVTGDjn/uOcq/d+mQ2keJ9fBMxzztU45zYDG4Gp3sdG51yBc64WmOdd\nV1qxKK+YCIMzx/QPdCki0oVFdeC2rgNe9D4fTGM4NCn0tgFsP6x9WgfW8CUXPPQx1XUN/nwLv9qx\n9yDpQxNJ7NEt0KWISBd21DAwsyxgQAuL7nbOLfCuczdQDzzXkcWZ2Y3AjQBDhgxp1zbS+vWgtsHT\nkWV1qpHJPblq2tBAlyEiXdxRw8A5N+NIy83sW8DXgLOcc87bXASkNlstxdvGEdpbeu+5wFyA9PR0\n19p6R/LXKye152UiImHF19FE5wI/Bi50zlU1W/Q6cKWZxZjZcGAksARYCow0s+Fm1o3GTubXfalB\nRER852ufwcNADLDIzACynXM3O+fWmtlLQB6Np4++65xrADCzW4GFQCTwhHNurY81iIiIj+y/Z3aC\nW3p6usvNzQ10GSIiIcPMljnn0tuyrq5AFhERhYGIiCgMREQEhYGIiKAwEBERQmg0kZntBrYGuo4A\n6QvsCXQRAaTPr8+vz98+Q51z/dqyYsiEQTgzs9y2Dg/rivT59fn1+f3/+XWaSEREFAYiIqIwCBVz\nA11AgOnzhzd9/k6gPgMREdGRgYiIKAwCwsxSzew9M8szs7Vmdpu3PdHMFpnZBu+/Cd52M7MHzWyj\nmX1mZpObbesa7/obzOyaQH2m9vDeF3uFmb3h/Xq4meV4P+eL3mnO8U6F/qK3PcfMhjXbxl3e9vVm\n9tXAfJJjZ2Z9zOwVM1tnZvlmlhlO+9/MfuD92V9jZi+YWWxX3/9m9oSZlZjZmmZtHbbPzWyKma32\nvuZB804l3WbOOT06+QEMBCZ7n8cDnwPjgD8Cd3rb7wT+4H1+HvA2YEAGkONtTwQKvP8meJ8nBPrz\nHcP34YfA88Ab3q9fAq70Pn8E+I73+S3AI97nVwIvep+PA1bROI36cGATEBnoz9XGz/4UcL33eTeg\nT7jsfxpvgbsZ6N5sv3+rq+9/4FRgMrCmWVuH7XMa7xmT4X3N28DMY6ov0N8gPRzAAuBsYD0w0Ns2\nEFjvff4oMLvZ+uu9y2cDjzZr/8J6wfyg8S537wBnAm94f4D3AFHe5ZnAQu/zhUCm93mUdz0D7gLu\narbNQ+sF8wPo7f1laIe1h8X+94bBdu8vtCjv/v9qOOx/YNhhYdAh+9y7bF2z9i+s15aHThMFmPeQ\ndxKQAyQ753Z6F+0Ckr3Pm/7zNCn0trXWHgr+SuNd8ppuUJ0E7HXO1Xu/bv5ZDn1O7/J93vVD9fMP\nB3YD//SeJnvMzHoQJvvfOVcE/BnYBuykcX8uI3z2f3Mdtc8He58f3t5mCoMAMrOewKvA7c65iubL\nXGO8d8mhXmb2NaDEObcs0LUESBSNpwv+4ZybBFTSeIrgkC6+/xOAi2gMxUFAD+DcgBYVBAK9zxUG\nAWJm0TQGwXPOude8zcVmNtC7fCBQ4m0vAlKbvTzF29Zae7D7CnChmW0B5tF4qugBoI+ZNd2Ktfln\nOfQ5vct7A6WE7ucvBAqdczner1+hMRzCZf/PADY753Y75+qA12j8mQiX/d9cR+3zIu/zw9vbTGEQ\nAN5e/seBfOfcfc0WvQ40jQ64hsa+hKb2Od4RBhnAPu+h5ULgHDNL8P61dY63Lag55+5yzqU454bR\n2CH4rnPuKuA94FLvaod//qbvy6Xe9Z23/UrvaJPhwEgaO9GCmnNuF7DdzEZ7m86i8X7hYbH/aTw9\nlGFmcd7/C02fPyz2/2E6ZJ97l1WYWYb3ezqn2bbaJtAdKuH4AE6m8XDwM2Cl93EejedB3wE2AFlA\nond9A/5G42iJ1UB6s21dB2z0Pq4N9Gdrx/fidP47mmgEjf+ZNwIvAzHe9ljv1xu9y0c0e/3d3u/L\neo5x9ESAP/dEINf7M/AvGkeGhM3+B34FrAPWAM/QOCKoS+9/4AUa+0jqaDw6/HZH7nMg3fv93AQ8\nzGEDFI720BXIIiKi00QiIqIwEBERFAYiIoLCQEREUBiIiAgKAxERQWEgIiIoDEREBPj/7AC0c0Qt\nd/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f730bf51320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iters, list(map(np.mean, session_rewards)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the $V(s)$ and  $\\pi(a|s)$\n",
    "\n",
    "Since the observation space is just 2-dimensional, we can plot it on a 2d scatter-plot to gain insight of what agent learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, _, _, (pool_policy, pool_V) = agent.get_sessions(\n",
    "    pool.experience_replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True)\n",
    "\n",
    "plt.scatter(\n",
    "    *pool.experience_replay.observations[0].get_value().reshape([-1,2]).T,\n",
    "    c = pool_V.ravel().eval(),\n",
    "    alpha = 0.1)\n",
    "plt.title(\"predicted state values\")\n",
    "plt.xlabel(\"position\")\n",
    "plt.ylabel(\"speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs_x,obs_y = pool.experience_replay.observations[0].get_value().reshape([-1,2]).T\n",
    "optimal_actid = pool_policy.argmax(-1).ravel().eval()\n",
    "action_names=[\"left\",\"stop\",\"right\"]\n",
    "for i in range(3):\n",
    "    sel = optimal_actid==i\n",
    "    plt.scatter(obs_x[sel],obs_y[sel],\n",
    "                c=['red','blue','green'][i],\n",
    "                alpha = 0.1,label=action_names[i])\n",
    "    \n",
    "plt.title(\"most likely action id\")\n",
    "plt.xlabel(\"position\")\n",
    "plt.ylabel(\"speed\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variations in the algorithm (2 pts)\n",
    "\n",
    "Try different `n_steps` param to see if it improves learning performance.\n",
    "\n",
    "Your objective is to compare learning curves for 1, 3, 10 and 25-step updates (or any grid you think is appropriate).\n",
    "\n",
    "For 25-step updates, please also increase SEQ_LENGTH to 25.\n",
    "\n",
    "Also evaluate how performance changes with different entropy regularizer coefficient.\n",
    "\n",
    "_bonus_ See if you can learn effectively without experience replay (may need a lot of parallel agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<a lot of your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bonus section (5+ pts)\n",
    "\n",
    "Beat the [`LunarLanderContinuous-v2`](https://gym.openai.com/envs/LunarLanderContinuous-v2) with continuous version of advantage actor-critic.\n",
    "\n",
    "You will require a multidimensional gaussian (or similar) policy from your agent.\n",
    "\n",
    "You can implement that by feeding a2c.get_elementwise_objective probabilities of agent's chosen actions (it will be 2-dimensional) instead of all actions.\n",
    "\n",
    "Contact us if you have any questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
